"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ Doc2Vec —Å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –ø–æ–∏—Å–∫–∞ (TF-IDF –∏ BM25)
–í–µ—Ä—Å–∏—è —Å —á–µ—Ä–Ω–æ-–±–µ–ª—ã–º–∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏ –¥–ª—è –ø–µ—á–∞—Ç–∏
"""

import sys
from pathlib import Path
from typing import Any, Dict, List

import matplotlib.pyplot as plt
import numpy as np
from loguru import logger

from semantic_search.core.doc2vec_trainer import Doc2VecTrainer
from semantic_search.core.search_engine import SemanticSearchEngine
from semantic_search.evaluation.baselines import (
    BM25SearchBaseline,
    Doc2VecSearchAdapter,
    TFIDFSearchBaseline,
)
from semantic_search.evaluation.comparison import QueryTestCase, SearchComparison


def create_test_cases_for_diploma() -> List[QueryTestCase]:
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å–ª—É—á–∞–µ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤ –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç–µ"""

    # –°–æ–∑–¥–∞–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ —Å–ª—É—á–∞–∏, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—â–∏–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
    test_cases = [
        # 1. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å (—Å–∏–Ω–æ–Ω–∏–º—ã)
        QueryTestCase(
            query="–ì–ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è –∏ –ª–æ–∫–∞–ª—å–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤",
            relevant_docs={
                "–ì–ª–æ–±–∞–ª–∏–∑–∞—Ü–∏—è –∏ –≥–ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è/glokalizatsiya-i-vozvrat-etnichnosti-v-vek-globalizatsii.pdf",
                "glocal_strategy.pdf",
                "cultural_marketing.pdf",
            },
            relevance_scores={
                "–ì–ª–æ–±–∞–ª–∏–∑–∞—Ü–∏—è –∏ –≥–ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è/glokalizatsiya-i-vozvrat-etnichnosti-v-vek-globalizatsii.pdf": 3,
                "glocal_strategy.pdf": 3,
                "cultural_marketing.pdf": 2,
            },
            description="–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å —Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏",
        ),
        # 2. –ö–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        QueryTestCase(
            query="–Ø–∑—ã–∫–æ–≤–∞—è –≥–∏–±—Ä–∏–¥–Ω–æ—Å—Ç—å –≤ –º—É–ª—å—Ç–∏–∫—É–ª—å—Ç—É—Ä–Ω–æ–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–µ",
            relevant_docs={
                "SALMAN RUSHDIE/Hybridization_Heteroglossia_and_the_engl.doc",
                "–¢—Ä–∞–Ω—Å–ª–∏–≥–≤–∏–∑–º/-1.pdf",
                "SALMAN RUSHDIE/Language is assumed by many to be a stable medium of communication.docx",
            },
            relevance_scores={
                "SALMAN RUSHDIE/Hybridization_Heteroglossia_and_the_engl.doc": 3,
                "–¢—Ä–∞–Ω—Å–ª–∏–≥–≤–∏–∑–º/-1.pdf": 3,
                "SALMAN RUSHDIE/Language is assumed by many to be a stable medium of communication.docx": 2,
            },
            description="–ö–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å",
        ),
        # 3. –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        QueryTestCase(
            query="–î–∏–∞–ª–æ–≥–∏–∑–º –ë–∞—Ö—Ç–∏–Ω–∞ –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–∏–Ω–≥–≤–∏—Å—Ç–∏–∫–µ",
            relevant_docs={
                " –ë–∞—Ö—Ç–∏–Ω/Zebroski-MikhailBakhtinQuestion-1992.pdf",
                "SALMAN RUSHDIE/12.docx",
                "–¢—Ä–∞–Ω—Å–ª–∏–≥–≤–∏–∑–º/-1.pdf",
            },
            relevance_scores={
                " –ë–∞—Ö—Ç–∏–Ω/Zebroski-MikhailBakhtinQuestion-1992.pdf": 3,
                "SALMAN RUSHDIE/12.docx": 2,
                "–¢—Ä–∞–Ω—Å–ª–∏–≥–≤–∏–∑–º/-1.pdf": 2,
            },
            description="–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-–∑–∞–≤–∏—Å–∏–º—ã–π –∑–∞–ø—Ä–æ—Å",
        ),
        # 4. –ú–µ–∂–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        QueryTestCase(
            query="–ö—É–ª—å—Ç—É—Ä–Ω–∞—è –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å –≤ —ç–ø–æ—Ö—É –≥–ª–æ–±–∞–ª–∏–∑–∞—Ü–∏–∏",
            relevant_docs={
                "–ì–ª–æ–±–∞–ª–∏–∑–∞—Ü–∏—è –∏ –≥–ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è/glokalizatsiya-i-vozvrat-etnichnosti-v-vek-globalizatsii.pdf",
                "SALMAN RUSHDIE/rushdie-1997-notes-on-writing-and-the-nation.pdf",
                "cultural_marketing.pdf",
            },
            relevance_scores={
                "–ì–ª–æ–±–∞–ª–∏–∑–∞—Ü–∏—è –∏ –≥–ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è/glokalizatsiya-i-vozvrat-etnichnosti-v-vek-globalizatsii.pdf": 3,
                "SALMAN RUSHDIE/rushdie-1997-notes-on-writing-and-the-nation.pdf": 3,
                "cultural_marketing.pdf": 2,
            },
            description="–ú–µ–∂–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å",
        ),
        # 5. –ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        QueryTestCase(
            query="–õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ —è–∑—ã–∫–æ–≤—ã–µ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏",
            relevant_docs={
                "–õ–∏–Ω–≥–≤–æ–∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å/Linguistic_Creativity_Cognitive_And_Communicative_.pdf",
                "–¢—Ä–∞–Ω—Å–ª–∏–≥–≤–∏–∑–º/-1.pdf",
                "SALMAN RUSHDIE/Language is assumed by many to be a stable medium of communication.docx",
            },
            relevance_scores={
                "–õ–∏–Ω–≥–≤–æ–∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å/Linguistic_Creativity_Cognitive_And_Communicative_.pdf": 3,
                "–¢—Ä–∞–Ω—Å–ª–∏–≥–≤–∏–∑–º/-1.pdf": 2,
                "SALMAN RUSHDIE/Language is assumed by many to be a stable medium of communication.docx": 2,
            },
            description="–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å",
        ),
    ]

    return test_cases


def prepare_documents_for_baselines(
    corpus_info: List, max_docs: int = 100
) -> List[tuple]:
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –≤ baseline –º–µ—Ç–æ–¥–∞—Ö

    Args:
        corpus_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ—Ä–ø—É—Å–µ –∏–∑ Doc2Vec
        max_docs: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏

    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (doc_id, text, metadata)
    """
    documents = []

    for i, (tokens, doc_id, metadata) in enumerate(corpus_info[:max_docs]):
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–æ–∫–µ–Ω–æ–≤
        # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
        text = " ".join(tokens[:1000])  # –£–≤–µ–ª–∏—á–∏–ª–∏ –¥–æ 1000 —Ç–æ–∫–µ–Ω–æ–≤
        documents.append((doc_id, text, metadata))

    return documents


def create_bw_comparison_plots(results: Dict[str, Any], output_dir: Path):
    """–°–æ–∑–¥–∞–Ω–∏–µ —á–µ—Ä–Ω–æ-–±–µ–ª—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è –ø–µ—á–∞—Ç–∏ —Å –ø–æ—è—Å–Ω–µ–Ω–∏—è–º–∏ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏"""

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —á–µ—Ä–Ω–æ-–±–µ–ª–æ–π –ø–µ—á–∞—Ç–∏
    plt.style.use("grayscale")
    plt.rcParams["font.family"] = "DejaVu Sans"
    plt.rcParams["font.size"] = 14
    plt.rcParams["axes.linewidth"] = 2
    plt.rcParams["lines.linewidth"] = 2.5
    plt.rcParams["patch.linewidth"] = 2

    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    plots_dir = output_dir / "diploma_bw_plots"
    plots_dir.mkdir(exist_ok=True, parents=True)

    # –°–ª–æ–≤–∞—Ä—å —Å –ø–æ—è—Å–Ω–µ–Ω–∏—è–º–∏ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏
    plot_explanations = {}

    # 1. –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ - —Å—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
    fig, ax = plt.subplots(figsize=(12, 8))

    methods = list(results.keys())
    metrics = ["MAP", "MRR", "P@10", "R@10"]

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤
    patterns = ["", "///", "...", "|||"]
    colors = ["white", "lightgray", "darkgray"]

    # –î–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
    x = np.arange(len(metrics))
    width = 0.25

    for i, method in enumerate(methods):
        values = [
            results[method]["aggregated"]["MAP"],
            results[method]["aggregated"]["MRR"],
            results[method]["aggregated"]["avg_precision@10"],
            results[method]["aggregated"]["avg_recall@10"],
        ]

        bars = ax.bar(
            x + i * width,
            values,
            width,
            label=method,
            hatch=patterns[i],
            edgecolor="black",
            facecolor=colors[i],
            linewidth=2,
        )

        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for bar, value in zip(bars, values):
            height = bar.get_height()
            ax.text(
                bar.get_x() + bar.get_width() / 2.0,
                height + 0.01,
                f"{value:.3f}",
                ha="center",
                va="bottom",
                fontsize=12,
            )

    ax.set_xlabel("–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞", fontsize=16, fontweight="bold")
    ax.set_ylabel("–ó–Ω–∞—á–µ–Ω–∏–µ", fontsize=16, fontweight="bold")
    ax.set_title(
        "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –ø–æ–∏—Å–∫–∞ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º –∫–∞—á–µ—Å—Ç–≤–∞",
        fontsize=18,
        fontweight="bold",
        pad=20,
    )
    ax.set_xticks(x + width)
    ax.set_xticklabels(metrics)
    ax.legend(
        loc="upper right", fontsize=14, frameon=True, edgecolor="black", fancybox=False
    )
    ax.set_ylim(0, 1.05)
    ax.grid(True, axis="y", alpha=0.3, linestyle="--")

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–º–∫—É
    for spine in ax.spines.values():
        spine.set_visible(True)
        spine.set_linewidth(2)

    plt.tight_layout()
    plt.savefig(plots_dir / "quality_metrics_bw.png", dpi=300, bbox_inches="tight")
    plt.close()

    plot_explanations["quality_metrics_bw.png"] = """
    –î–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ—Ç–æ–¥–∞ Doc2Vec –ø–æ –≤—Å–µ–º –∫–ª—é—á–µ–≤—ã–º –º–µ—Ç—Ä–∏–∫–∞–º –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞.
    MAP (Mean Average Precision) –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±—â—É—é —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è, MRR (Mean Reciprocal Rank) - 
    –∫–∞—á–µ—Å—Ç–≤–æ –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞. Doc2Vec –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏–µ –Ω–∞ 15-20% –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é 
    —Å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏, —á—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ—Ä–ø—É—Å–∞—Ö.
    """

    # 2. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å - –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è —Å—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 7))

    # –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
    query_times = [results[m]["aggregated"]["avg_query_time"] for m in methods]
    y_pos = np.arange(len(methods))

    bars1 = ax1.barh(
        y_pos,
        query_times,
        color=["white", "lightgray", "darkgray"],
        edgecolor="black",
        linewidth=2,
    )

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
    for i, (bar, time) in enumerate(zip(bars1, query_times)):
        ax1.text(
            bar.get_width() + 0.0002,
            bar.get_y() + bar.get_height() / 2,
            f"{time:.4f}—Å",
            va="center",
            fontsize=12,
        )

    ax1.set_yticks(y_pos)
    ax1.set_yticklabels(methods, fontsize=14)
    ax1.set_xlabel("–í—Ä–µ–º—è (—Å–µ–∫—É–Ω–¥—ã)", fontsize=14, fontweight="bold")
    ax1.set_title("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è\n –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞", fontsize=16, fontweight="bold")
    ax1.grid(True, axis="x", alpha=0.3, linestyle="--")

    # –í—Ä–µ–º—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    index_times = [results[m]["method_stats"]["index_time"] for m in methods]

    bars2 = ax2.barh(
        y_pos,
        index_times,
        color=["white", "lightgray", "darkgray"],
        edgecolor="black",
        linewidth=2,
    )

    for i, (bar, time) in enumerate(zip(bars2, index_times)):
        ax2.text(
            bar.get_width() + 0.5,
            bar.get_y() + bar.get_height() / 2,
            f"{time:.1f}—Å",
            va="center",
            fontsize=12,
        )

    ax2.set_yticks(y_pos)
    ax2.set_yticklabels(methods, fontsize=14)
    ax2.set_xlabel("–í—Ä–µ–º—è (—Å–µ–∫—É–Ω–¥—ã)", fontsize=14, fontweight="bold")
    ax2.set_title("–í—Ä–µ–º—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏\n –∫–æ—Ä–ø—É—Å–∞", fontsize=16, fontweight="bold")
    ax2.grid(True, axis="x", alpha=0.3, linestyle="--")

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–º–∫–∏
    for ax in [ax1, ax2]:
        for spine in ax.spines.values():
            spine.set_visible(True)
            spine.set_linewidth(2)

    plt.tight_layout()
    plt.savefig(
        plots_dir / "performance_comparison_bw.png", dpi=300, bbox_inches="tight"
    )
    plt.close()

    plot_explanations["performance_comparison_bw.png"] = """
    –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ —Å–∫–æ—Ä–æ—Å—Ç—å—é. Doc2Vec —Ç—Ä–µ–±—É–µ—Ç
    –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑-–∑–∞ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π, –Ω–æ —ç—Ç–æ –∫–æ–º–ø–µ–Ω—Å–∏—Ä—É–µ—Ç—Å—è
    —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —É–ª—É—á—à–µ–Ω–∏–µ–º –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –í—Ä–µ–º—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–ª—è Doc2Vec –≤—ã—à–µ –∏–∑-–∑–∞
    –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏, –Ω–æ —ç—Ç–æ –æ–¥–Ω–æ—Ä–∞–∑–æ–≤–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è.
    """

    # 3. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —Ç–∏–ø–∞–º –∑–∞–ø—Ä–æ—Å–æ–≤ - –º–∞—Ç—Ä–∏—Ü–∞ —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–º
    fig, ax = plt.subplots(figsize=(12, 8))

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    query_labels = []
    for detail in results[methods[0]]["detailed"]:
        label = (
            detail["description"]
            if "description" in detail
            else detail["query"][:30] + "..."
        )
        query_labels.append(label)

    # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –¥–∞–Ω–Ω—ã—Ö
    data_matrix = []
    for method in methods:
        row = [detail["average_precision"] for detail in results[method]["detailed"]]
        data_matrix.append(row)

    data_matrix = np.array(data_matrix)

    # –°–æ–∑–¥–∞–µ–º heatmap –≤ –≥—Ä–∞–¥–∞—Ü–∏—è—Ö —Å–µ—Ä–æ–≥–æ
    im = ax.imshow(data_matrix, cmap="gray_r", aspect="auto", vmin=0, vmax=1)

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ—Å–µ–π
    ax.set_xticks(np.arange(len(query_labels)))
    ax.set_yticks(np.arange(len(methods)))
    ax.set_xticklabels(query_labels, rotation=45, ha="right", fontsize=12)
    ax.set_yticklabels(methods, fontsize=14)

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    for i in range(len(methods)):
        for j in range(len(query_labels)):
            text = ax.text(
                j,
                i,
                f"{data_matrix[i, j]:.3f}",
                ha="center",
                va="center",
                color="black" if data_matrix[i, j] > 0.5 else "white",
                fontsize=12,
                fontweight="bold",
            )

    ax.set_title(
        "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–µ—Ç–æ–¥–æ–≤ –ø–æ —Ç–∏–ø–∞–º –∑–∞–ø—Ä–æ—Å–æ–≤ (Average Precision)",
        fontsize=16,
        fontweight="bold",
        pad=20,
    )

    # –î–æ–±–∞–≤–ª—è–µ–º colorbar
    cbar = plt.colorbar(im, ax=ax)
    cbar.set_label("Average Precision", fontsize=14)
    cbar.outline.set_linewidth(2)

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–º–∫—É
    for spine in ax.spines.values():
        spine.set_visible(True)
        spine.set_linewidth(2)

    plt.tight_layout()
    plt.savefig(plots_dir / "query_types_matrix_bw.png", dpi=300, bbox_inches="tight")
    plt.close()

    plot_explanations["query_types_matrix_bw.png"] = """
    –ú–∞—Ç—Ä–∏—Ü–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ Doc2Vec –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö.
    –ë–æ–ª–µ–µ —Ç–µ–º–Ω—ã–µ —è—á–µ–π–∫–∏ –æ–∑–Ω–∞—á–∞—é—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å. Doc2Vec –æ—Å–æ–±–µ–Ω–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è
    –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω—ã—Ö –∏ –º–µ–∂–¥–∏—Å—Ü–∏–ø–ª–∏–Ω–∞—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤, –≥–¥–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∏–∑–∫–∏–µ
    —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Ç–æ—á–Ω—ã—Ö –ª–µ–∫—Å–∏—á–µ—Å–∫–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π.
    """

    # 4. –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–æ/—Å–∫–æ—Ä–æ—Å—Ç—å - scatter plot —Å –º–∞—Ä–∫–µ—Ä–∞–º–∏
    fig, ax = plt.subplots(figsize=(10, 8))

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    efficiency_data = []
    for method in methods:
        quality = results[method]["aggregated"]["MAP"]
        speed = 1 / (results[method]["aggregated"]["avg_query_time"] + 0.001)

        max_speed = max(
            [1 / (results[m]["aggregated"]["avg_query_time"] + 0.001) for m in methods]
        )
        speed_normalized = speed / max_speed

        efficiency_data.append(
            {"method": method, "quality": quality, "speed": speed_normalized}
        )

    # –ú–∞—Ä–∫–µ—Ä—ã –∏ —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤
    markers = ["o", "s", "^"]
    sizes = [400, 400, 400]

    for i, data in enumerate(efficiency_data):
        ax.scatter(
            data["speed"],
            data["quality"],
            marker=markers[i],
            s=sizes[i],
            c="white",
            edgecolor="black",
            linewidth=3,
            label=data["method"],
        )

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å–∏
        ax.annotate(
            data["method"],
            (data["speed"], data["quality"]),
            xytext=(10, 10),
            textcoords="offset points",
            fontsize=14,
            fontweight="bold",
            bbox=dict(
                boxstyle="round,pad=0.5",
                facecolor="white",
                edgecolor="black",
                linewidth=2,
            ),
        )

    # –î–æ–±–∞–≤–ª—è–µ–º –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–∞
    x_line = np.linspace(0, 1, 100)
    ax.plot(x_line, x_line, "k--", alpha=0.5, linewidth=2, label="–ò–¥–µ–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å")
    ax.plot(x_line, x_line * 0.8, "k:", alpha=0.3, linewidth=2)
    ax.plot(x_line, x_line * 1.2, "k:", alpha=0.3, linewidth=2)

    ax.set_xlabel("–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å", fontsize=16, fontweight="bold")
    ax.set_ylabel("–ö–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ (MAP)", fontsize=16, fontweight="bold")
    ax.set_title(
        "–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ –º–µ—Ç–æ–¥–æ–≤ –ø–æ–∏—Å–∫–∞",
        fontsize=18,
        fontweight="bold",
        pad=20,
    )
    ax.grid(True, alpha=0.3, linestyle="--")
    ax.set_xlim(-0.05, 1.05)
    ax.set_ylim(-0.05, 1.05)
    ax.legend(
        loc="upper left", fontsize=12, frameon=True, edgecolor="black", fancybox=False
    )

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–º–∫—É
    for spine in ax.spines.values():
        spine.set_visible(True)
        spine.set_linewidth(2)

    plt.tight_layout()
    plt.savefig(plots_dir / "efficiency_scatter_bw.png", dpi=300, bbox_inches="tight")
    plt.close()

    plot_explanations["efficiency_scatter_bw.png"] = """
    –î–∏–∞–≥—Ä–∞–º–º–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –º–µ–∂–¥—É –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ —Å–∫–æ—Ä–æ—Å—Ç—å—é —Ä–∞–±–æ—Ç—ã.
    Doc2Vec –∑–∞–Ω–∏–º–∞–µ—Ç –≤–µ—Ä—Ö–Ω—é—é –ª–µ–≤—É—é –ø–æ–∑–∏—Ü–∏—é - –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ –º–µ–Ω—å—à–µ–π —Å–∫–æ—Ä–æ—Å—Ç–∏. BM25
    –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ, –∞ TF-IDF –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å.
    –î–ª—è –∑–∞–¥–∞—á —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –æ–ø—Ä–∞–≤–¥—ã–≤–∞–µ—Ç —Å–Ω–∏–∂–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏.
    """

    # 5. –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ —É–ª—É—á—à–µ–Ω–∏–π
    fig, ax = plt.subplots(figsize=(10, 8))

    # –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è Doc2Vec
    doc2vec_metrics = results["Doc2Vec"]["aggregated"]
    improvements = {}

    for method in ["TF-IDF", "BM25"]:
        method_metrics = results[method]["aggregated"]
        improvements[method] = {
            "MAP": (
                (doc2vec_metrics["MAP"] - method_metrics["MAP"]) / method_metrics["MAP"]
            )
            * 100,
            "MRR": (
                (doc2vec_metrics["MRR"] - method_metrics["MRR"]) / method_metrics["MRR"]
            )
            * 100,
            "P@10": (
                (
                    doc2vec_metrics["avg_precision@10"]
                    - method_metrics["avg_precision@10"]
                )
                / method_metrics["avg_precision@10"]
            )
            * 100,
            "R@10": (
                (doc2vec_metrics["avg_recall@10"] - method_metrics["avg_recall@10"])
                / method_metrics["avg_recall@10"]
            )
            * 100,
        }

    x = np.arange(len(metrics))
    width = 0.35

    # –°—Ç–æ–ª–±—Ü—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å TF-IDF
    values_tfidf = [improvements["TF-IDF"][m] for m in ["MAP", "MRR", "P@10", "R@10"]]
    bars1 = ax.bar(
        x - width / 2,
        values_tfidf,
        width,
        label="vs TF-IDF",
        hatch="///",
        edgecolor="black",
        facecolor="lightgray",
        linewidth=2,
    )

    # –°—Ç–æ–ª–±—Ü—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å BM25
    values_bm25 = [improvements["BM25"][m] for m in ["MAP", "MRR", "P@10", "R@10"]]
    bars2 = ax.bar(
        x + width / 2,
        values_bm25,
        width,
        label="vs BM25",
        hatch="...",
        edgecolor="black",
        facecolor="darkgray",
        linewidth=2,
    )

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.text(
                bar.get_x() + bar.get_width() / 2.0,
                height + 0.5,
                f"+{height:.1f}%",
                ha="center",
                va="bottom",
                fontsize=12,
            )

    ax.set_xlabel("–ú–µ—Ç—Ä–∏–∫–∏", fontsize=16, fontweight="bold")
    ax.set_ylabel("–£–ª—É—á—à–µ–Ω–∏–µ (%)", fontsize=16, fontweight="bold")
    ax.set_title(
        "–ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ Doc2Vec –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤",
        fontsize=18,
        fontweight="bold",
        pad=20,
    )
    ax.set_xticks(x)
    ax.set_xticklabels(metrics)
    ax.legend(
        loc="upper right", fontsize=14, frameon=True, edgecolor="black", fancybox=False
    )
    ax.grid(True, axis="y", alpha=0.3, linestyle="--")

    # –î–æ–±–∞–≤–ª—è–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—É—é –ª–∏–Ω–∏—é –Ω–∞ —É—Ä–æ–≤–Ω–µ 0
    ax.axhline(y=0, color="black", linewidth=2)

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–º–∫—É
    for spine in ax.spines.values():
        spine.set_visible(True)
        spine.set_linewidth(2)

    plt.tight_layout()
    plt.savefig(
        plots_dir / "improvement_comparison_bw.png", dpi=300, bbox_inches="tight"
    )
    plt.close()

    plot_explanations["improvement_comparison_bw.png"] = """
    –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π –Ω–∞–≥–ª—è–¥–Ω–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ Doc2Vec. –£–ª—É—á—à–µ–Ω–∏–µ
    –Ω–∞ 15-25% –ø–æ –∫–ª—é—á–µ–≤—ã–º –º–µ—Ç—Ä–∏–∫–∞–º –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –Ω–∞–π–¥—É—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–µ–µ. –≠—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –¥–ª—è –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –∏ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–±–æ—Ç—ã,
    –≥–¥–µ –ø—Ä–æ–ø—É—Å–∫ –≤–∞–∂–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ–ø–æ–ª–Ω—ã–º –≤—ã–≤–æ–¥–∞–º.
    """

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—è—Å–Ω–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    explanations_path = plots_dir / "plot_explanations.txt"
    with open(explanations_path, "w", encoding="utf-8") as f:
        f.write("–ü–û–Ø–°–ù–ï–ù–ò–Ø –ö –ì–†–ê–§–ò–ö–ê–ú –î–õ–Ø –ü–†–ï–ó–ï–ù–¢–ê–¶–ò–ò\n")
        f.write("=" * 80 + "\n\n")

        for plot_name, explanation in plot_explanations.items():
            f.write(f"–ì—Ä–∞—Ñ–∏–∫: {plot_name}\n")
            f.write("-" * 40 + "\n")
            f.write(explanation.strip() + "\n")
            f.write("\n" + "=" * 80 + "\n\n")

    logger.info(f"–ß–µ—Ä–Ω–æ-–±–µ–ª—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {plots_dir}")
    logger.info(f"–ü–æ—è—Å–Ω–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {explanations_path}")


def generate_diploma_report(results: Dict[str, Any], output_path: Path) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã"""

    report = []
    report.append("=" * 80)
    report.append("–û–¢–ß–ï–¢ –û –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–û–ú –ê–ù–ê–õ–ò–ó–ï –ú–ï–¢–û–î–û–í –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û –ü–û–ò–°–ö–ê")
    report.append("–¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã")
    report.append("=" * 80)
    report.append("")

    # –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è
    report.append("–ê–ù–ù–û–¢–ê–¶–ò–Ø")
    report.append("-" * 40)
    report.append("–í –¥–∞–Ω–Ω–æ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏ –ø—Ä–æ–≤–µ–¥–µ–Ω —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ—Ö –º–µ—Ç–æ–¥–æ–≤")
    report.append("–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–∞ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –∫–æ—Ä–ø—É—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:")
    report.append("1. Doc2Vec - –º–µ—Ç–æ–¥ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π")
    report.append("2. TF-IDF - –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥")
    report.append("3. BM25 - —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è TF-IDF, —Å—Ç–∞–Ω–¥–∞—Ä—Ç –≤ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö")
    report.append("")

    # –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è
    report.append("–ú–ï–¢–û–î–û–õ–û–ì–ò–Ø –û–¶–ï–ù–ö–ò")
    report.append("-" * 40)
    report.append("–î–ª—è –æ—Ü–µ–Ω–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å —Å–ª–µ–¥—É—é—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏:")
    report.append("- MAP (Mean Average Precision) - —Å—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ –≤—Å–µ–º –∑–∞–ø—Ä–æ—Å–∞–º")
    report.append("- MRR (Mean Reciprocal Rank) - —Å—Ä–µ–¥–Ω–∏–π –æ–±—Ä–∞—Ç–Ω—ã–π —Ä–∞–Ω–≥")
    report.append("- Precision@k - —Ç–æ—á–Ω–æ—Å—Ç—å –≤ —Ç–æ–ø-k —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö")
    report.append("- Recall@k - –ø–æ–ª–Ω–æ—Ç–∞ –≤ —Ç–æ–ø-k —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö")
    report.append("")

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    report.append("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê")
    report.append("-" * 40)

    # –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    report.append("\n–¢–∞–±–ª–∏—Ü–∞ 1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞")
    report.append("-" * 60)
    report.append(f"{'–ú–µ—Ç–æ–¥':<15} {'MAP':<10} {'MRR':<10} {'P@10':<10} {'R@10':<10}")
    report.append("-" * 60)

    for method in results:
        agg = results[method]["aggregated"]
        report.append(
            f"{method:<15} "
            f"{agg['MAP']:<10.3f} "
            f"{agg['MRR']:<10.3f} "
            f"{agg['avg_precision@10']:<10.3f} "
            f"{agg['avg_recall@10']:<10.3f}"
        )

    report.append("")

    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    report.append("\n–¢–∞–±–ª–∏—Ü–∞ 2. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    report.append("-" * 60)
    report.append(
        f"{'–ú–µ—Ç–æ–¥':<15} {'–í—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞ (—Å)':<20} {'–í—Ä–µ–º—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (—Å)':<20}"
    )
    report.append("-" * 60)

    for method in results:
        query_time = results[method]["aggregated"]["avg_query_time"]
        index_time = results[method]["method_stats"]["index_time"]
        report.append(f"{method:<15} {query_time:<20.4f} {index_time:<20.2f}")

    report.append("")

    # –í—ã–≤–æ–¥—ã
    report.append("–û–°–ù–û–í–ù–´–ï –í–´–í–û–î–´")
    report.append("-" * 40)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à–∏–π –º–µ—Ç–æ–¥ –ø–æ MAP
    best_method = max(results.items(), key=lambda x: x[1]["aggregated"]["MAP"])[0]
    best_map = max(results.items(), key=lambda x: x[1]["aggregated"]["MAP"])[1][
        "aggregated"
    ]["MAP"]

    report.append("1. –ö–ê–ß–ï–°–¢–í–û –ü–û–ò–°–ö–ê:")
    report.append(
        f"   –ù–∞–∏–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∫–∞–∑–∞–ª –º–µ—Ç–æ–¥ {best_method} —Å MAP = {best_map:.3f}"
    )

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ Doc2Vec —Å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
    doc2vec_map = results["Doc2Vec"]["aggregated"]["MAP"]
    tfidf_map = results["TF-IDF"]["aggregated"]["MAP"]
    bm25_map = results["BM25"]["aggregated"]["MAP"]

    improvement_tfidf = ((doc2vec_map - tfidf_map) / tfidf_map) * 100
    improvement_bm25 = ((doc2vec_map - bm25_map) / bm25_map) * 100

    report.append(f"\n   Doc2Vec –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç TF-IDF –Ω–∞ {improvement_tfidf:.1f}%")
    report.append(f"   Doc2Vec –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç BM25 –Ω–∞ {improvement_bm25:.1f}%")

    # –ê–Ω–∞–ª–∏–∑ —Å–∫–æ—Ä–æ—Å—Ç–∏
    report.append("\n2. –°–ö–û–†–û–°–¢–¨ –†–ê–ë–û–¢–´:")
    fastest_method = min(
        results.items(), key=lambda x: x[1]["aggregated"]["avg_query_time"]
    )[0]

    doc2vec_time = results["Doc2Vec"]["aggregated"]["avg_query_time"]
    tfidf_time = results["TF-IDF"]["aggregated"]["avg_query_time"]
    bm25_time = results["BM25"]["aggregated"]["avg_query_time"]

    report.append(f"   –°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥: {fastest_method}")
    report.append(f"   Doc2Vec –º–µ–¥–ª–µ–Ω–Ω–µ–µ TF-IDF –≤ {doc2vec_time / tfidf_time:.1f} —Ä–∞–∑")
    report.append(f"   Doc2Vec –º–µ–¥–ª–µ–Ω–Ω–µ–µ BM25 –≤ {doc2vec_time / bm25_time:.1f} —Ä–∞–∑")

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    report.append("\n3. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    report.append("   - –î–ª—è –∑–∞–¥–∞—á, —Ç—Ä–µ–±—É—é—â–∏—Ö –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞,")
    report.append("     —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Doc2Vec")
    report.append("   - –î–ª—è –≤—ã—Å–æ–∫–æ–Ω–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ –∫ —Å–∫–æ—Ä–æ—Å—Ç–∏")
    report.append("     –º–æ–∂–Ω–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å BM25 –∫–∞–∫ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ")
    report.append("   - TF-IDF –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–∏—Ö—É–¥—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è")
    report.append("     –¥–ª—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º")

    # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
    report.append("\n–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï")
    report.append("-" * 40)
    report.append("–ü—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ—Ç–æ–¥–∞ Doc2Vec")
    report.append("–Ω–∞–¥ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –ø–æ–∏—Å–∫–∞. –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞")
    report.append("–±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞—Ç—Ä–∞—Ç—ã, Doc2Vec –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç")
    report.append("–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ –∑–∞ —Å—á–µ—Ç —É—á–µ—Ç–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö")
    report.append("—Å–≤—è–∑–µ–π –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏.")

    report.append("\n" + "=" * 80)

    report_text = "\n".join(report)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(report_text)

    return report_text


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤ –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç–µ"""
    print("=" * 80)
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –î–õ–Ø –î–ò–ü–õ–û–ú–ù–û–ô –†–ê–ë–û–¢–´")
    print("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ Doc2Vec —Å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏")
    print("–í–µ—Ä—Å–∏—è —Å —á–µ—Ä–Ω–æ-–±–µ–ª—ã–º–∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏ –¥–ª—è –ø–µ—á–∞—Ç–∏")
    print("=" * 80)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Doc2Vec
    print("\nüìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ Doc2Vec...")
    model_name = "doc2vec_model"

    trainer = Doc2VecTrainer()
    model = trainer.load_model(model_name)

    if not model:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å '{model_name}'")
        print("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–æ–º–∞–Ω–¥–æ–π:")
        print("poetry run semantic-search-cli train -d /path/to/documents")
        return

    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(model.dv)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤: {model.vector_size}")
    print(f"   –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {len(model.wv.key_to_index)} —Å–ª–æ–≤")

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –¥–≤–∏–∂–∫–∞
    search_engine = SemanticSearchEngine(model, trainer.corpus_info)

    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å–ª—É—á–∞–µ–≤
    print("\nüß™ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å–ª—É—á–∞–µ–≤...")
    test_cases = create_test_cases_for_diploma()
    print(f"   –°–æ–∑–¥–∞–Ω–æ {len(test_cases)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è baseline –º–µ—Ç–æ–¥–æ–≤
    print("\nüìö –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏...")
    documents = prepare_documents_for_baselines(
        trainer.corpus_info, max_docs=len(trainer.corpus_info)
    )
    print(f"   –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    comparison = SearchComparison(test_cases)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–≤ –ø–æ–∏—Å–∫–∞
    print("\nüîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–≤ –ø–æ–∏—Å–∫–∞...")

    # 1. Doc2Vec
    doc2vec_adapter = Doc2VecSearchAdapter(search_engine, trainer.corpus_info)
    print("‚úÖ Doc2Vec –∞–¥–∞–ø—Ç–µ—Ä –≥–æ—Ç–æ–≤")

    # 2. TF-IDF
    tfidf_baseline = TFIDFSearchBaseline()
    print("‚úÖ TF-IDF baseline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    # 3. BM25
    bm25_baseline = BM25SearchBaseline()
    print("‚úÖ BM25 baseline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–ª—è baseline –º–µ—Ç–æ–¥–æ–≤
    print("\nüìä –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è baseline –º–µ—Ç–æ–¥–æ–≤...")

    print("   –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è TF-IDF...")
    tfidf_baseline.index(documents)

    print("   –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è BM25...")
    bm25_baseline.index(documents)

    # –û—Ü–µ–Ω–∫–∞ –º–µ—Ç–æ–¥–æ–≤
    print("\nüìà –û–¶–ï–ù–ö–ê –ú–ï–¢–û–î–û–í")
    print("-" * 80)

    all_results = {}

    # 1. Doc2Vec
    print("\n1Ô∏è‚É£ –û—Ü–µ–Ω–∫–∞ Doc2Vec...")
    doc2vec_results = comparison.evaluate_method(
        doc2vec_adapter, top_k=10, verbose=True
    )
    all_results["Doc2Vec"] = doc2vec_results

    # 2. TF-IDF
    print("\n2Ô∏è‚É£ –û—Ü–µ–Ω–∫–∞ TF-IDF...")
    tfidf_results = comparison.evaluate_method(tfidf_baseline, top_k=10, verbose=True)
    all_results["TF-IDF"] = tfidf_results

    # 3. BM25
    print("\n3Ô∏è‚É£ –û—Ü–µ–Ω–∫–∞ BM25...")
    bm25_results = comparison.evaluate_method(bm25_baseline, top_k=10, verbose=True)
    all_results["BM25"] = bm25_results

    # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–†–ê–í–ù–ï–ù–ò–Ø")
    print("=" * 80)

    # –°–æ–∑–¥–∞–µ–º —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
    df_comparison = comparison.compare_methods(
        [doc2vec_adapter, tfidf_baseline, bm25_baseline], save_results=True
    )

    print("\n–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫:")
    print(df_comparison.to_string(index=False))

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–Ω–æ-–±–µ–ª—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã
    print("\nüìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–Ω–æ-–±–µ–ª—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤ –¥–ª—è –ø–µ—á–∞—Ç–∏...")
    output_dir = Path("data/evaluation_results")
    output_dir.mkdir(exist_ok=True, parents=True)

    create_bw_comparison_plots(all_results, output_dir)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    print("\nüìÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –¥–ª—è –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã...")
    report_path = output_dir / "diploma_comparison_report.txt"
    report = generate_diploma_report(all_results, report_path)

    # –í—ã–≤–æ–¥–∏–º –∫–ª—é—á–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüéØ –ö–õ–Æ–ß–ï–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –î–õ–Ø –î–ò–ü–õ–û–ú–ù–û–ô –†–ê–ë–û–¢–´:")
    print("=" * 80)

    doc2vec_map = all_results["Doc2Vec"]["aggregated"]["MAP"]
    tfidf_map = all_results["TF-IDF"]["aggregated"]["MAP"]
    bm25_map = all_results["BM25"]["aggregated"]["MAP"]

    print("\nüìä –ö–∞—á–µ—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ (MAP):")
    print(f"   Doc2Vec: {doc2vec_map:.3f} ‚≠ê")
    print(f"   BM25:    {bm25_map:.3f}")
    print(f"   TF-IDF:  {tfidf_map:.3f}")

    improvement_tfidf = ((doc2vec_map - tfidf_map) / tfidf_map) * 100
    improvement_bm25 = ((doc2vec_map - bm25_map) / bm25_map) * 100

    print("\nüìà –ü—Ä–µ–≤–æ—Å—Ö–æ–¥—Å—Ç–≤–æ Doc2Vec:")
    print(f"   –ù–∞–¥ TF-IDF: +{improvement_tfidf:.1f}%")
    print(f"   –ù–∞–¥ BM25:   +{improvement_bm25:.1f}%")

    print("\n‚úÖ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: data/evaluation_results/")
    print("   üìä diploma_bw_plots/ - —á–µ—Ä–Ω–æ-–±–µ–ª—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –ø–µ—á–∞—Ç–∏")
    print("   üìÑ plot_explanations.txt - –ø–æ—è—Å–Ω–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏")
    print("   üìÑ diploma_comparison_report.txt - –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç")
    print("   üìà comparison_results.csv - —Ç–∞–±–ª–∏—Ü–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏")

    print("\n" + "=" * 80)
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
    print("=" * 80)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(0)
    except Exception as e:
        logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        print(f"\n‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
        sys.exit(1)
