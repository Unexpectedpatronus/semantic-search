
	
	\chapter{АНАЛИТИЧЕСКИЙ РАЗДЕЛ}
	
	\section{Анализ предметной области}
	
	\justifying
	
	Информационный поиск является одной из фундаментальных задач в области компьютерных наук. С ростом объемов цифровой информации традиционные методы поиска, основанные на точном соответствии ключевых слов, становятся недостаточно эффективными. Пользователи ожидают от поисковых систем понимания контекста и смысла запросов, способности находить релевантные документы даже при использовании различной терминологии.
	
	Основные проблемы традиционного поиска включают:
	
	1. Лексическая вариативность – один и тот же концепт может быть выражен различными словами и фразами.
	
	2. Полисемия – одно слово может иметь множество значений в зависимости от контекста.
	
	3. Языковые барьеры – в многоязычных коллекциях документов традиционный поиск неэффективен.
	
	4. Сложные информационные потребности – пользователи часто не могут точно сформулировать запрос.
	
	Семантический поиск призван решить эти проблемы путем анализа смыслового содержания документов и запросов. Ключевой идеей является представление текстов в виде векторов в многомерном семантическом пространстве, где близость векторов соответствует смысловой близости текстов.
	
	\section{Обзор существующих методов информационного поиска}
	
	Эволюция методов информационного поиска прошла несколько этапов. Рассмотрим основные подходы:
	
	\textbf{Булев поиск} – самый простой метод, основанный на точном соответствии терминов с использованием логических операторов AND, OR, NOT. Преимущества: простота реализации, предсказуемость результатов. Недостатки: отсутствие ранжирования, жесткие критерии соответствия.
	
	\textbf{Векторная модель и TF-IDF} – документы и запросы представляются как векторы в пространстве терминов. Вес термина вычисляется по формуле:
	
	\begin{equation}
		w_{i,j} = tf_{i,j} \times \log\frac{N}{df_i} \quad,
	\end{equation}
	
	\noindent где $tf_{i,j}$ – частота термина $i$ в документе $j$, $N$ – общее количество документов, $df_i$ – количество документов, содержащих термин $i$.
	
	Релевантность определяется косинусным сходством векторов:
	
	\begin{equation}
		\text{similarity}(d_j, q) = \frac{\vec{d_j} \cdot \vec{q}}{|\vec{d_j}| \times |\vec{q}|} \quad.
	\end{equation}
	
	\textbf{Вероятностная модель BM25} – улучшенная версия TF-IDF с нормализацией длины документа:
	
	\begin{equation}
		\text{score}(D,Q) = \sum_{i=1}^{n} IDF(q_i) \cdot \frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{\text{avgdl}})}  \quad,
	\end{equation}
	
	\noindent где $f(q_i, D)$ – частота термина $q_i$ в документе $D$, $|D|$ – длина документа, $\text{avgdl}$ – средняя длина документа в коллекции, $k_1$ и $b$ – свободные параметры.
	
	\textbf{Латентно-семантический анализ (LSA)} – использует сингулярное разложение матрицы термин-документ для выявления скрытых семантических связей. Основная идея – редукция размерности пространства признаков с сохранением наиболее важной информации.
	
	\textbf{Нейросетевые подходы} – современные методы, использующие глубокое обучение для создания плотных векторных представлений текстов. К ним относятся Word2Vec, GloVe, BERT, и исследуемый в данной работе Doc2Vec.
	
	\section{Анализ технологий машинного обучения для обработки текстов}
	
	Применение машинного обучения в обработке естественного языка привело к качественному скачку в решении задач понимания и генерации текста. Рассмотрим ключевые технологии:
	
	\textbf{Word2Vec} – пионерская технология создания векторных представлений слов, предложенная Томашем Миколовым в 2013 году. Существует две архитектуры:
	
	1. Continuous Bag of Words (CBOW) – предсказывает слово по контексту.
	2. Skip-gram – предсказывает контекст по слову.
	
	Обучение основано на максимизации логарифмической вероятности:
	
	\begin{equation}
		\mathcal{L} = \frac{1}{T}\sum_{t=1}^{T}\sum_{-c \leq j \leq c, j \neq 0} \log p(w_{t+j}|w_t)  \quad,
	\end{equation}
	
	\noindent где $T$ – размер корпуса, $c$ – размер окна контекста.
	
	\textbf{Doc2Vec} – расширение Word2Vec для представления документов произвольной длины. Добавляется специальный вектор документа, который обучается совместно с векторами слов. Существует два режима:
	
	1. Distributed Memory (DM) – аналог CBOW с добавлением вектора документа.
	2. Distributed Bag of Words (DBOW) – предсказывает слова документа по его вектору.
	
	\textbf{Transformer и BERT} – современные архитектуры, основанные на механизме внимания (attention). BERT использует двунаправленный контекст и предобучение на больших корпусах текстов. Несмотря на высокое качество, требует значительных вычислительных ресурсов.
	
	Для задач семантического поиска в корпоративной среде Doc2Vec представляет оптимальный баланс между качеством и вычислительными требованиями.
	
	\section{Сравнительный анализ алгоритмов векторного представления документов}
	
	Проведем сравнительный анализ основных подходов к векторному представлению документов по ключевым критериям:
	
	\begin{table}[H]
		\caption{Сравнение методов векторного представления документов}
		\begin{center}
			\begin{tabular}{|p{3cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|}
				\hline
				\textbf{Критерий} & \textbf{TF-IDF} & \textbf{LSA} & \textbf{Doc2Vec} & \textbf{BERT} \\
				\hline
				Размерность вектора & Высокая (размер словаря) & Средняя (50-500) & Низкая (100-400) & Средняя (768) \\
				\hline
				Учет семантики & Нет & Частично & Да & Да \\
				\hline
				Скорость обучения & Очень быстро & Быстро & Средне & Медленно \\
				\hline
				Требования к памяти & Высокие & Средние & Низкие & Очень высокие \\
				\hline
				Качество для коротких текстов & Низкое & Среднее & Хорошее & Отличное \\
				\hline
				Качество для длинных документов & Среднее & Хорошее & Отличное & Хорошее \\
				\hline
			\end{tabular}
		\end{center}
	\end{table}
	
	Анализ показывает, что Doc2Vec обладает оптимальными характеристиками для решения поставленной задачи:
	
	1. Низкая размерность векторов обеспечивает эффективное хранение и быстрый поиск.
	2. Учет семантических связей позволяет находить релевантные документы даже при отсутствии точных совпадений терминов.
	3. Хорошая масштабируемость – можно обучать на больших корпусах документов.
	4. Поддержка инкрементального обучения – возможность дообучения модели на новых документах.
	
	\section{Выводы по аналитическому разделу}
	
	Проведенный анализ позволяет сделать следующие выводы:
	
	1. Традиционные методы информационного поиска (булев поиск, TF-IDF, BM25) имеют фундаментальные ограничения, связанные с отсутствием понимания семантики текста.
	
	2. Современные подходы на основе машинного обучения позволяют создавать плотные векторные представления документов, учитывающие семантические связи между словами и концептами.
	
	3. Алгоритм Doc2Vec представляет оптимальное решение для задачи семантического поиска в корпоративной среде, обеспечивая хороший баланс между качеством результатов и вычислительными требованиями.
	
	4. Для повышения качества поиска целесообразно использовать гибридный подход, сочетающий семантический поиск на основе Doc2Vec с классическими методами для обработки точных запросов.
	
	5. Важным аспектом является предобработка текстов, включающая токенизацию, лемматизацию и фильтрацию стоп-слов, что существенно влияет на качество обучения модели.
	
	Результаты аналитического исследования определяют выбор технологий и архитектурных решений для разработки системы семантического поиска.
	
\clearpage