"""–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"""

import sys
from pathlib import Path
from typing import Optional

import click
from loguru import logger

from semantic_search.config import GUI_CONFIG
from semantic_search.core.doc2vec_trainer import Doc2VecTrainer
from semantic_search.core.document_processor import DocumentProcessor
from semantic_search.core.search_engine import SemanticSearchEngine
from semantic_search.core.text_summarizer import TextSummarizer
from semantic_search.utils.logging_config import setup_logging
from semantic_search.utils.statistics import (
    calculate_model_statistics,
    calculate_statistics_from_processed_docs,
    format_statistics_for_display,
)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""

    setup_logging()
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º SpaCy –º–æ–¥–µ–ª—å –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    from semantic_search.utils.text_utils import check_spacy_model_availability

    spacy_info = check_spacy_model_availability()

    if not spacy_info["model_loadable"]:
        logger.warning(f"SpaCy –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {spacy_info['error']}")
        logger.info("–î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏: poetry run python scripts/setup_spacy.py")
    else:
        logger.info("‚úÖ SpaCy –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")

    logger.info("–ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è Semantic Document Search")

    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å PyQt6
        from PyQt6.QtCore import Qt
        from PyQt6.QtWidgets import QApplication

        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è Qt
        app = QApplication(sys.argv)
        app.setApplicationName(GUI_CONFIG["window_title"])
        app.setOrganizationName("Semantic Search")

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∏–ª—å
        app.setStyle("Fusion")  # –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å

        # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ –æ–∫–Ω–∞
        from semantic_search.gui.main_window import MainWindow

        main_window = MainWindow()
        main_window.show()

        logger.info("–ì–ª–∞–≤–Ω–æ–µ –æ–∫–Ω–æ —Å–æ–∑–¥–∞–Ω–æ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–æ")

        # –ó–∞–ø—É—Å–∫ —Ü–∏–∫–ª–∞ —Å–æ–±—ã—Ç–∏–π
        exit_code = app.exec()
        logger.info(f"–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —Å –∫–æ–¥–æ–º: {exit_code}")
        sys.exit(exit_code)

    except ImportError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã:")
        print("poetry install")
        sys.exit(1)

    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


@click.group()
def cli():
    """Semantic Document Search CLI"""
    setup_logging()


@cli.command()
@click.option("--documents", "-d", required=True, help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
@click.option("--model", "-m", default="doc2vec_model", help="–ò–º—è –º–æ–¥–µ–ª–∏")
@click.option("--vector-size", default=150, help="–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤")
@click.option("--epochs", default=40, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è")
def train(documents: str, model: str, vector_size: int, epochs: int):
    """
    –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å Doc2Vec –Ω–∞ –∫–æ—Ä–ø—É—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

    Args:
        documents: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        model: –ò–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        vector_size: –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤
        epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
    """

    documents_path = Path(documents)
    if not documents_path.exists():
        logger.error(f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {documents_path}")
        return

    logger.info("–†–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")

    # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    processor = DocumentProcessor()

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    processed_docs = list(processor.process_documents(documents_path))
    if not processed_docs:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∫–æ—Ä–ø—É—Å")
        return
    corpus = [(doc.tokens, doc.relative_path, doc.metadata) for doc in processed_docs]
    logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –∫–æ—Ä–ø—É—Å –∏–∑ {len(corpus)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    trainer = Doc2VecTrainer()
    trained_model = trainer.train_model(corpus, vector_size=vector_size, epochs=epochs)

    if trained_model:
        trainer.save_model(trained_model, model)
        logger.info("‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = calculate_statistics_from_processed_docs(processed_docs)
        click.echo(f"\n{format_statistics_for_display(stats)}")
    else:
        logger.error("‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")


@cli.command()
@click.option("--documents", "-d", required=True, help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
@click.option("--query", "-q", required=True, help="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
@click.option("--model", "-m", default="doc2vec_model", help="–ò–º—è –º–æ–¥–µ–ª–∏")
@click.option("--top-k", "-k", default=10, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
def search(documents: str, query: str, model: str, top_k: int):
    """
    –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º

    Args:
        documents: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        model: –ò–º—è –º–æ–¥–µ–ª–∏
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –≤—ã–≤–æ–¥–∞
    """
    logger.info(f"–†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞: {query}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    trainer = Doc2VecTrainer()
    loaded_model = trainer.load_model(model)

    if loaded_model is None:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
        click.echo("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–æ–º–∞–Ω–¥–æ–π: train")
        return

    # –ü–æ–∏—Å–∫
    search_engine = SemanticSearchEngine(loaded_model, trainer.corpus_info)
    results = search_engine.search(query, top_k=top_k)

    if results:
        click.echo(f"\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è '{query}':")
        click.echo("=" * 50)
        for i, result in enumerate(results, 1):
            click.echo(f"{i}. {result.doc_id}")
            click.echo(f"   üìä –°—Ö–æ–¥—Å—Ç–≤–æ: {result.similarity:.3f}")
            if result.metadata:
                tokens_count = result.metadata.get("tokens_count", "N/A")
                file_size = result.metadata.get("file_size", 0)
                click.echo(f"   üìù –¢–æ–∫–µ–Ω–æ–≤: {tokens_count}, –†–∞–∑–º–µ—Ä: {file_size} –±–∞–π—Ç")
            click.echo()
    else:
        click.echo(f"‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}'")


@cli.command()
@click.option("--documents", "-d", help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
@click.option("--model", "-m", default="doc2vec_model", help="–ò–º—è –º–æ–¥–µ–ª–∏")
def stats(documents: Optional[str], model: str):
    """
    –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–æ–¥–µ–ª–∏ –∏ –∫–æ—Ä–ø—É—Å–∞

    Args:
        documents: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        model: –ò–º—è –º–æ–¥–µ–ª–∏
    """
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ—Ä–ø—É—Å–∞
    if documents:
        documents_path = Path(documents)
        if documents_path.exists():
            processor = DocumentProcessor()
            processed_docs = list(processor.process_documents(documents_path))

            if processed_docs:
                stats_data = calculate_statistics_from_processed_docs(processed_docs)
                click.echo(format_statistics_for_display(stats_data))
            else:
                click.echo("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã")
        else:
            click.echo(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {documents_path}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏
    trainer = Doc2VecTrainer()
    if trainer.load_model(model):
        model_info = trainer.get_model_info()
        click.echo(f"\n{calculate_model_statistics(model_info)}")
    else:
        click.echo(f"\n‚ùå –ú–æ–¥–µ–ª—å '{model}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")


# –ö–û–ú–ê–ù–î–´ –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–ò


@cli.command()
@click.option("--file", "-f", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏")
@click.option("--model", "-m", default="doc2vec_model", help="–ò–º—è Doc2Vec –º–æ–¥–µ–ª–∏")
@click.option("--sentences", "-s", default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ")
@click.option("--output", "-o", help="–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∂–∏–º–∫–∏")
def summarize_file(
    file: str, model: str, sentences: int, output: Optional[str]
) -> None:
    """
    –°–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫—É –∏–∑ —Ñ–∞–π–ª–∞

    Args:
        file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        model: –ò–º—è Doc2Vec –º–æ–¥–µ–ª–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        sentences: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ
        output: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∂–∏–º–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """
    file_path = Path(file)
    if not file_path.exists():
        click.echo(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Doc2Vec
    trainer = Doc2VecTrainer()
    loaded_model = trainer.load_model(model)

    if loaded_model is None:
        click.echo("‚ö†Ô∏è –ú–æ–¥–µ–ª—å Doc2Vec –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è")
        summarizer = TextSummarizer()
    else:
        click.echo("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å Doc2Vec")
        summarizer = TextSummarizer(loaded_model)

    logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –≤—ã–∂–∏–º–∫–∏ —Ñ–∞–π–ª–∞: {file_path}")

    # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã–∂–∏–º–∫–∏
    try:
        summary = summarizer.summarize_file(str(file_path), sentences_count=sentences)

        if not summary:
            click.echo(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞"
            )
            return

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –∫–æ–Ω—Å–æ–ª—å
        click.echo(f"\nüìÑ –í—ã–∂–∏–º–∫–∞ —Ñ–∞–π–ª–∞: {file_path.name}")
        click.echo("=" * 60)

        for i, sentence in enumerate(summary, 1):
            click.echo(f"{i}. {sentence.strip()}")
            click.echo()  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        try:
            from semantic_search.utils.file_utils import FileExtractor

            extractor = FileExtractor()
            original_text = extractor.extract_text(file_path)

            if original_text:
                stats = summarizer.get_summary_statistics(original_text, summary)

                click.echo("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:")
                click.echo("-" * 30)
                click.echo(
                    f"  üìë –ò—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['original_sentences_count']}"
                )
                click.echo(
                    f"  üìÑ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_sentences_count']}"
                )
                click.echo(
                    f"  üìâ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['compression_ratio']:.1%}"
                )
                click.echo(f"  üî§ –ò—Å—Ö–æ–¥–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤: {stats['original_chars_count']:,}")
                click.echo(f"  ‚úÇÔ∏è –°–∏–º–≤–æ–ª–æ–≤ –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_chars_count']:,}")
                click.echo(
                    f"  üìä –°–æ–∫—Ä–∞—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞: {stats['chars_compression_ratio']:.1%}"
                )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
        if output:
            output_path = Path(output)
            try:
                with open(output_path, "w", encoding="utf-8") as f:
                    f.write(f"–í—ã–∂–∏–º–∫–∞ —Ñ–∞–π–ª–∞: {file_path.name}\n")
                    f.write(
                        f"–°–æ–∑–¥–∞–Ω–æ: {click.get_current_context().meta.get('timestamp', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n"
                    )
                    f.write("=" * 60 + "\n\n")

                    for i, sentence in enumerate(summary, 1):
                        f.write(f"{i}. {sentence.strip()}\n\n")

                    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ —Ñ–∞–π–ª
                    if "stats" in locals():
                        f.write("\n" + "=" * 60 + "\n")
                        f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–ò\n")
                        f.write("=" * 60 + "\n")
                        f.write(
                            f"–ò—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['original_sentences_count']}\n"
                        )
                        f.write(
                            f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_sentences_count']}\n"
                        )
                        f.write(
                            f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['compression_ratio']:.1%}\n"
                        )
                        f.write(
                            f"–ò—Å—Ö–æ–¥–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤: {stats['original_chars_count']:,}\n"
                        )
                        f.write(
                            f"–°–∏–º–≤–æ–ª–æ–≤ –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_chars_count']:,}\n"
                        )
                        f.write(
                            f"–°–æ–∫—Ä–∞—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞: {stats['chars_compression_ratio']:.1%}\n"
                        )

                click.echo(f"üíæ –í—ã–∂–∏–º–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {output_path}")

            except Exception as e:
                click.echo(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤—ã–∂–∏–º–∫–∏: {e}")

    except Exception as e:
        click.echo(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤—ã–∂–∏–º–∫–∏: {e}")
        logger.error(f"–û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")


@cli.command()
@click.option("--text", "-t", required=True, help="–¢–µ–∫—Å—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏")
@click.option("--model", "-m", default="doc2vec_model", help="–ò–º—è Doc2Vec –º–æ–¥–µ–ª–∏")
@click.option("--sentences", "-s", default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ")
@click.option("--output", "-o", help="–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∂–∏–º–∫–∏")
def summarize_text(
    text: str, model: str, sentences: int, output: Optional[str]
) -> None:
    """
    –°–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫—É –∏–∑ —Ç–µ–∫—Å—Ç–∞

    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (—Å—Ç—Ä–æ–∫–∞)
        model: –ò–º—è Doc2Vec –º–æ–¥–µ–ª–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        sentences: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ
        output: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∂–∏–º–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """
    # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    if not text or len(text.strip()) < 100:
        click.echo("‚ùå –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (–º–∏–Ω–∏–º—É–º 100 —Å–∏–º–≤–æ–ª–æ–≤)")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
    temp_processor = TextSummarizer()
    original_sentences = temp_processor.text_processor.split_into_sentences(text)

    if len(original_sentences) <= sentences:
        click.echo(
            f"‚ö†Ô∏è –í —Ç–µ–∫—Å—Ç–µ –≤—Å–µ–≥–æ {len(original_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —á—Ç–æ –º–µ–Ω—å—à–µ –∏–ª–∏ —Ä–∞–≤–Ω–æ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É ({sentences})"
        )
        click.echo("–í—ã–≤–æ–¥–∏–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç:")
        for i, sentence in enumerate(original_sentences, 1):
            click.echo(f"{i}. {sentence.strip()}")
        return

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Doc2Vec
    trainer = Doc2VecTrainer()
    loaded_model = trainer.load_model(model)

    if loaded_model is None:
        click.echo("‚ö†Ô∏è –ú–æ–¥–µ–ª—å Doc2Vec –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è")
        summarizer = TextSummarizer()
    else:
        click.echo("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å Doc2Vec")
        summarizer = TextSummarizer(loaded_model)

    logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –≤—ã–∂–∏–º–∫–∏ —Ç–µ–∫—Å—Ç–∞")

    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã–∂–∏–º–∫–∏
        summary = summarizer.summarize_text(text, sentences_count=sentences)

        if not summary:
            click.echo("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫—É")
            return

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        click.echo("\nüìÑ –í—ã–∂–∏–º–∫–∞ —Ç–µ–∫—Å—Ç–∞:")
        click.echo("=" * 60)

        for i, sentence in enumerate(summary, 1):
            click.echo(f"{i}. {sentence.strip()}")
            click.echo()  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        stats = summarizer.get_summary_statistics(text, summary)

        click.echo("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:")
        click.echo("-" * 30)
        click.echo(f"  üìë –ò—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['original_sentences_count']}")
        click.echo(f"  üìÑ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_sentences_count']}")
        click.echo(
            f"  üìâ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['compression_ratio']:.1%}"
        )
        click.echo(f"  üî§ –ò—Å—Ö–æ–¥–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤: {stats['original_chars_count']:,}")
        click.echo(f"  ‚úÇÔ∏è –°–∏–º–≤–æ–ª–æ–≤ –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_chars_count']:,}")
        click.echo(f"  üìä –°–æ–∫—Ä–∞—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞: {stats['chars_compression_ratio']:.1%}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
        if output:
            output_path = Path(output)
            try:
                with open(output_path, "w", encoding="utf-8") as f:
                    f.write("–í—ã–∂–∏–º–∫–∞ —Ç–µ–∫—Å—Ç–∞\n")
                    f.write("=" * 60 + "\n\n")

                    for i, sentence in enumerate(summary, 1):
                        f.write(f"{i}. {sentence.strip()}\n\n")

                    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    f.write("\n" + "=" * 60 + "\n")
                    f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–ò\n")
                    f.write("=" * 60 + "\n")
                    f.write(
                        f"–ò—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['original_sentences_count']}\n"
                    )
                    f.write(
                        f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_sentences_count']}\n"
                    )
                    f.write(
                        f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['compression_ratio']:.1%}\n"
                    )
                    f.write(f"–ò—Å—Ö–æ–¥–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤: {stats['original_chars_count']:,}\n")
                    f.write(f"–°–∏–º–≤–æ–ª–æ–≤ –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_chars_count']:,}\n")
                    f.write(
                        f"–°–æ–∫—Ä–∞—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞: {stats['chars_compression_ratio']:.1%}\n"
                    )

                click.echo(f"üíæ –í—ã–∂–∏–º–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {output_path}")

            except Exception as e:
                click.echo(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤—ã–∂–∏–º–∫–∏: {e}")

    except Exception as e:
        click.echo(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤—ã–∂–∏–º–∫–∏: {e}")
        logger.error(f"–û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")


@cli.command()
@click.option("--documents", "-d", required=True, help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
@click.option("--model", "-m", default="doc2vec_model", help="–ò–º—è Doc2Vec –º–æ–¥–µ–ª–∏")
@click.option(
    "--sentences",
    "-s",
    default=3,
    help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞",
)
@click.option("--output-dir", "-o", help="–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∂–∏–º–æ–∫")
@click.option(
    "--extensions", default="pdf,docx,doc", help="–†–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)"
)
@click.option(
    "--max-files",
    default=0,
    help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ)",
)
def summarize_batch(
    documents: str,
    model: str,
    sentences: int,
    output_dir: Optional[str],
    extensions: str,
    max_files: int,
) -> None:
    """
    –°–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫–∏ –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –ø–∞–ø–∫–µ

    Args:
        documents: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        model: –ò–º—è Doc2Vec –º–æ–¥–µ–ª–∏
        sentences: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –∫–∞–∂–¥–æ–π –≤—ã–∂–∏–º–∫–µ
        output_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∂–∏–º–æ–∫
        extensions: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
        max_files: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ (0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)
    """
    documents_path = Path(documents)
    if not documents_path.exists():
        click.echo(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {documents_path}")
        return

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Doc2Vec
    trainer = Doc2VecTrainer()
    loaded_model = trainer.load_model(model)

    if loaded_model is None:
        click.echo("‚ö†Ô∏è –ú–æ–¥–µ–ª—å Doc2Vec –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è")
        summarizer = TextSummarizer()
    else:
        click.echo("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å Doc2Vec")
        summarizer = TextSummarizer(loaded_model)

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
    allowed_extensions = {f".{ext.strip().lower()}" for ext in extensions.split(",")}
    click.echo(f"üîç –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏: {allowed_extensions}")

    # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤
    all_files = []
    for file_path in documents_path.rglob("*"):
        if file_path.is_file() and file_path.suffix.lower() in allowed_extensions:
            all_files.append(file_path)

    if not all_files:
        click.echo(f"‚ùå –§–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ {allowed_extensions} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤
    if max_files > 0 and len(all_files) > max_files:
        all_files = all_files[:max_files]
        click.echo(f"üìÅ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ –¥–æ {max_files} —Ñ–∞–π–ª–æ–≤ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö")

    click.echo(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(all_files)}")

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞–ø–∫–∏ –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    if output_dir:
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True, parents=True)
        click.echo(f"üíæ –í—ã–∂–∏–º–∫–∏ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")
    else:
        click.echo("üì∫ –í—ã–∂–∏–º–∫–∏ –±—É–¥—É—Ç –≤—ã–≤–µ–¥–µ–Ω—ã —Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Å–æ–ª—å")

    successful = 0
    failed = 0

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
    for i, file_path in enumerate(all_files, 1):
        click.echo(f"\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {i}/{len(all_files)}: {file_path.name}")

        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã–∂–∏–º–∫–∏
            summary = summarizer.summarize_file(
                str(file_path), sentences_count=sentences
            )

            if not summary:
                click.echo(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫—É –¥–ª—è {file_path.name}")
                failed += 1
                continue

            # –ö—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
            click.echo(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–∞ –≤—ã–∂–∏–º–∫–∞: {len(summary)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∫–∞–∫ –ø—Ä–µ–≤—å—é
            if summary:
                preview = (
                    summary[0][:100] + "..." if len(summary[0]) > 100 else summary[0]
                )
                click.echo(f"   üëÅÔ∏è –ü—Ä–µ–≤—å—é: {preview}")

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
            if output_dir:
                summary_filename = f"{file_path.stem}_summary.txt"
                summary_path = output_path / summary_filename

                try:
                    with open(summary_path, "w", encoding="utf-8") as f:
                        f.write(f"–í—ã–∂–∏–º–∫–∞ —Ñ–∞–π–ª–∞: {file_path.name}\n")
                        f.write(f"–ò—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å: {file_path}\n")
                        f.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {len(summary)}\n")
                        f.write("=" * 60 + "\n\n")

                        for j, sentence in enumerate(summary, 1):
                            f.write(f"{j}. {sentence.strip()}\n\n")

                    click.echo(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {summary_filename}")
                except Exception as save_error:
                    click.echo(f"   ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {save_error}")
                    failed += 1
                    continue

            successful += 1

        except Exception as e:
            click.echo(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}")
            failed += 1

    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    click.echo("\nüìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:")
    click.echo("=" * 50)
    click.echo(f"  ‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {successful}")
    click.echo(f"  ‚ùå –û—à–∏–±–æ–∫: {failed}")
    click.echo(f"  üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(all_files)}")
    click.echo(f"  üìà –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {(successful / len(all_files) * 100):.1f}%")

    if output_dir and successful > 0:
        click.echo(f"  üíæ –í—ã–∂–∏–º–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")


def cli_mode():
    """–ó–∞–ø—É—Å–∫ CLI —Ä–µ–∂–∏–º–∞"""
    cli()


if __name__ == "__main__":
    if len(sys.argv) > 1:
        cli_mode()
    else:
        main()
