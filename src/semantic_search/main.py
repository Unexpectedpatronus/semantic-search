"""–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"""

import sys
import time
from pathlib import Path
from typing import Optional

import click
from loguru import logger

from semantic_search.config import GUI_CONFIG, SPACY_MODEL
from semantic_search.core.doc2vec_trainer import Doc2VecTrainer
from semantic_search.core.document_processor import DocumentProcessor
from semantic_search.core.search_engine import SemanticSearchEngine
from semantic_search.core.text_summarizer import TextSummarizer
from semantic_search.utils.file_utils import FileExtractor
from semantic_search.utils.logging_config import setup_logging
from semantic_search.utils.notification_system import notification_manager
from semantic_search.utils.performance_monitor import PerformanceMonitor
from semantic_search.utils.statistics import (
    calculate_model_statistics,
    calculate_statistics_from_processed_docs,
    format_statistics_for_display,
)
from semantic_search.utils.task_manager import task_manager
from semantic_search.utils.text_utils import check_spacy_model_availability
from semantic_search.utils.validators import DataValidator, FileValidator

performance_monitor = PerformanceMonitor()


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""

    notification_manager.start()

    try:
        setup_logging()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ SpaCy —Å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ–º
        spacy_info = check_spacy_model_availability()
        if not spacy_info["model_loadable"]:
            notification_manager.warning(
                "SpaCy –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω",
                f"–ú–æ–¥–µ–ª—å {SPACY_MODEL} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞",
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: poetry run python scripts/setup_spacy.py",
            )
        else:
            notification_manager.success(
                "SpaCy –≥–æ—Ç–æ–≤", "–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ"
            )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å PyQt6
        try:
            from PyQt6.QtWidgets import QApplication

            from semantic_search.gui.main_window import MainWindow
        except ImportError as e:
            logger.error(f"PyQt6 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}")
            notification_manager.error(
                "–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞",
                "PyQt6 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω",
                "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: poetry install",
            )
            print("\n‚ùå PyQt6 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
            print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫–æ–º–∞–Ω–¥–æ–π: poetry install")
            print("\n–í—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CLI —Ä–µ–∂–∏–º:")
            print("poetry run semantic-search-cli --help")
            sys.exit(1)

        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è Qt
        app = QApplication(sys.argv)
        app.setApplicationName(GUI_CONFIG["window_title"])
        app.setOrganizationName("Semantic Search")

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∏–ª—å
        app.setStyle("Fusion")  # –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å

        # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ –æ–∫–Ω–∞
        main_window = MainWindow()
        main_window.show()

        logger.info("–ì–ª–∞–≤–Ω–æ–µ –æ–∫–Ω–æ —Å–æ–∑–¥–∞–Ω–æ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–æ")

        # –ó–∞–ø—É—Å–∫ —Ü–∏–∫–ª–∞ —Å–æ–±—ã—Ç–∏–π
        exit_code = app.exec()
        logger.info(f"–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —Å –∫–æ–¥–æ–º: {exit_code}")
        sys.exit(exit_code)

    except Exception as e:
        notification_manager.error(
            "–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞", "–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è", str(e)
        )
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print("\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –¥–ª—è –¥–µ—Ç–∞–ª–µ–π")
        sys.exit(1)
    finally:
        notification_manager.stop()
        task_manager.shutdown()


@click.group()
def cli():
    """Semantic Document Search CLI"""
    setup_logging()


@cli.command()
@click.option("--documents", "-d", required=True, help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
@click.option("--model", "-m", default="doc2vec_model", help="–ò–º—è –º–æ–¥–µ–ª–∏")
@click.option("--vector-size", default=150, help="–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤")
@click.option("--epochs", default=40, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è")
@click.option("--async-mode", "-a", is_flag=True, help="–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ")
def train(documents: str, model: str, vector_size: int, epochs: int, async_mode: bool):
    """
    –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å Doc2Vec –Ω–∞ –∫–æ—Ä–ø—É—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

    Args:
        documents: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        model: –ò–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        vector_size: –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤
        epochs: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è
    """
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        documents_path = DataValidator.validate_directory_path(Path(documents))
        model_params = DataValidator.validate_model_params(
            vector_size=vector_size, epochs=epochs
        )

        logger.info("–í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ")

    except Exception as e:
        click.echo(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        return

    def train_task(progress_tracker=None):
        """–ó–∞–¥–∞—á–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""

        with performance_monitor.measure_operation("document_processing"):
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            processor = DocumentProcessor()
            processed_docs = []

            file_extractor = FileExtractor()
            file_paths = file_extractor.find_documents(documents_path)

            if progress_tracker:
                progress_tracker.total_steps = len(file_paths) + epochs + 2
                progress_tracker.update(0, "–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")

            for i, doc in enumerate(processor.process_documents(documents_path)):
                processed_docs.append(doc)
                if progress_tracker:
                    progress_tracker.update(
                        i + 1, f"–û–±—Ä–∞–±–æ—Ç–∞–Ω –¥–æ–∫—É–º–µ–Ω—Ç: {doc.relative_path}"
                    )

            if not processed_docs:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã")

            corpus = [
                (doc.tokens, doc.relative_path, doc.metadata) for doc in processed_docs
            ]

            if progress_tracker:
                progress_tracker.update(message="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–∏...")

        with performance_monitor.measure_operation("model_training"):
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            trainer = Doc2VecTrainer()

            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –ø—Ä–æ–≥—Ä–µ—Å—Å —Ç—Ä–µ–∫–∏–Ω–≥–æ–º
            class ProgressDoc2Vec:
                def __init__(self, trainer, progress_tracker):
                    self.trainer = trainer
                    self.progress_tracker = progress_tracker

                def train_with_progress(self, corpus, **kwargs):
                    """–û–±—É—á–µ–Ω–∏–µ —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""

                    # –°–æ–∑–¥–∞–µ–º tagged documents
                    tagged_docs = self.trainer.create_tagged_documents(corpus)

                    from gensim.models.doc2vec import Doc2Vec

                    model = Doc2Vec(
                        vector_size=kwargs.get("vector_size", 150),
                        window=kwargs.get("window", 10),
                        min_count=kwargs.get("min_count", 2),
                        workers=kwargs.get("workers", 4),
                        seed=42,
                    )

                    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è
                    model.build_vocab(tagged_docs)

                    if self.progress_tracker:
                        self.progress_tracker.update(
                            message="–°–ª–æ–≤–∞—Ä—å –ø–æ—Å—Ç—Ä–æ–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ..."
                        )

                    # –û–±—É—á–µ–Ω–∏–µ –ø–æ —ç–ø–æ—Ö–∞–º
                    for epoch in range(kwargs.get("epochs", 40)):
                        model.train(
                            tagged_docs, total_examples=model.corpus_count, epochs=1
                        )

                        if self.progress_tracker:
                            progress_step = len(processed_docs) + epoch + 1
                            self.progress_tracker.update(
                                progress_step,
                                f"–≠–ø–æ—Ö–∞ {epoch + 1}/{kwargs.get('epochs', 40)}",
                            )

                    return model

            progress_trainer = ProgressDoc2Vec(trainer, progress_tracker)
            trained_model = progress_trainer.train_with_progress(
                corpus, vector_size=vector_size, epochs=epochs
            )

            if trained_model:
                trainer.model = trained_model
                trainer.corpus_info = corpus
                trainer.save_model(trained_model, model)

                if progress_tracker:
                    progress_tracker.finish("–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")

                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                stats = calculate_statistics_from_processed_docs(processed_docs)
                return {
                    "model_saved": True,
                    "documents_processed": len(processed_docs),
                    "vocabulary_size": len(trained_model.wv.key_to_index),
                    "statistics": stats,
                }
            else:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")

    if async_mode:
        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
        notification_manager.start()

        task_id = task_manager.submit_task(
            train_task,
            name=f"–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model}",
            description=f"–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –∏–∑ {documents_path}",
            track_progress=True,
            total_steps=100,  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤
        )

        click.echo(f"üîÑ –ó–∞–¥–∞—á–∞ –æ–±—É—á–µ–Ω–∏—è –∑–∞–ø—É—â–µ–Ω–∞ (ID: {task_id})")
        click.echo("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–∞–Ω–¥—É 'status' –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞")

        # –ü–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏
        def console_notification_handler(notification):
            if notification.type.value == "success":
                click.echo(f"‚úÖ {notification.title}: {notification.message}")
            elif notification.type.value == "error":
                click.echo(f"‚ùå {notification.title}: {notification.message}")
            elif notification.type.value == "warning":
                click.echo(f"‚ö†Ô∏è {notification.title}: {notification.message}")

        notification_manager.subscribe(console_notification_handler)

    else:
        # –°–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
        try:
            with performance_monitor.measure_operation("full_training"):
                result = train_task()

            click.echo("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
            click.echo(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {result['documents_processed']}")
            click.echo(f"üìö –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {result['vocabulary_size']:,}")

            # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats_display = format_statistics_for_display(result["statistics"])
            click.echo(f"\n{stats_display}")

        except Exception as e:
            click.echo(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}")
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")


@cli.command()
@click.option("--documents", "-d", required=True, help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
@click.option("--query", "-q", required=True, help="–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å")
@click.option("--model", "-m", default="doc2vec_model", help="–ò–º—è –º–æ–¥–µ–ª–∏")
@click.option("--top-k", "-k", default=10, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
def search(documents: str, query: str, model: str, top_k: int):
    """
    –ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º

    Args:
        documents: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        model: –ò–º—è –º–æ–¥–µ–ª–∏
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –≤—ã–≤–æ–¥–∞
    """
    logger.info(f"–†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞: {query}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    trainer = Doc2VecTrainer()
    loaded_model = trainer.load_model(model)

    if loaded_model is None:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å")
        click.echo("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–æ–º–∞–Ω–¥–æ–π: train")
        return

    # –ü–æ–∏—Å–∫
    search_engine = SemanticSearchEngine(loaded_model, trainer.corpus_info)
    results = search_engine.search(query, top_k=top_k)

    if results:
        click.echo(f"\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è '{query}':")
        click.echo("=" * 50)
        for i, result in enumerate(results, 1):
            click.echo(f"{i}. {result.doc_id}")
            click.echo(f"   üìä –°—Ö–æ–¥—Å—Ç–≤–æ: {result.similarity:.3f}")
            if result.metadata:
                tokens_count = result.metadata.get("tokens_count", "N/A")
                file_size = result.metadata.get("file_size", 0)
                click.echo(f"   üìù –¢–æ–∫–µ–Ω–æ–≤: {tokens_count}, –†–∞–∑–º–µ—Ä: {file_size} –±–∞–π—Ç")
            click.echo()
    else:
        click.echo(f"‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}'")


@cli.command()
@click.option("--documents", "-d", help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
@click.option("--model", "-m", default="doc2vec_model", help="–ò–º—è –º–æ–¥–µ–ª–∏")
def stats(documents: Optional[str], model: str):
    """
    –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –º–æ–¥–µ–ª–∏ –∏ –∫–æ—Ä–ø—É—Å–∞

    Args:
        documents: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        model: –ò–º—è –º–æ–¥–µ–ª–∏
    """
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ—Ä–ø—É—Å–∞
    if documents:
        documents_path = Path(documents)
        if documents_path.exists():
            processor = DocumentProcessor()
            processed_docs = list(processor.process_documents(documents_path))

            if processed_docs:
                stats_data = calculate_statistics_from_processed_docs(processed_docs)
                click.echo(format_statistics_for_display(stats_data))
            else:
                click.echo("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã")
        else:
            click.echo(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {documents_path}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏
    trainer = Doc2VecTrainer()
    if trainer.load_model(model):
        model_info = trainer.get_model_info()
        click.echo(f"\n{calculate_model_statistics(model_info)}")
    else:
        click.echo(f"\n‚ùå –ú–æ–¥–µ–ª—å '{model}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")


# –ö–û–ú–ê–ù–î–´ –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–ò


@cli.command()
@click.option("--file", "-f", required=True, help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏")
@click.option("--model", "-m", default="doc2vec_model", help="–ò–º—è Doc2Vec –º–æ–¥–µ–ª–∏")
@click.option("--sentences", "-s", default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ")
@click.option("--output", "-o", help="–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∂–∏–º–∫–∏")
def summarize_file(
    file: str, model: str, sentences: int, output: Optional[str]
) -> None:
    """
    –°–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫—É –∏–∑ —Ñ–∞–π–ª–∞

    Args:
        file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        model: –ò–º—è Doc2Vec –º–æ–¥–µ–ª–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        sentences: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ
        output: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∂–∏–º–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """
    file_path = Path(file)
    if not file_path.exists():
        click.echo(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Doc2Vec
    trainer = Doc2VecTrainer()
    loaded_model = trainer.load_model(model)

    if loaded_model is None:
        click.echo("‚ö†Ô∏è –ú–æ–¥–µ–ª—å Doc2Vec –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è")
        summarizer = TextSummarizer()
    else:
        click.echo("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å Doc2Vec")
        summarizer = TextSummarizer(loaded_model)

    logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –≤—ã–∂–∏–º–∫–∏ —Ñ–∞–π–ª–∞: {file_path}")

    # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã–∂–∏–º–∫–∏
    try:
        summary = summarizer.summarize_file(str(file_path), sentences_count=sentences)

        if not summary:
            click.echo(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞"
            )
            return

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –∫–æ–Ω—Å–æ–ª—å
        click.echo(f"\nüìÑ –í—ã–∂–∏–º–∫–∞ —Ñ–∞–π–ª–∞: {file_path.name}")
        click.echo("=" * 60)

        for i, sentence in enumerate(summary, 1):
            click.echo(f"{i}. {sentence.strip()}")
            click.echo()  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        try:
            from semantic_search.utils.file_utils import FileExtractor

            extractor = FileExtractor()
            original_text = extractor.extract_text(file_path)

            if original_text:
                stats = summarizer.get_summary_statistics(original_text, summary)

                click.echo("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:")
                click.echo("-" * 30)
                click.echo(
                    f"  üìë –ò—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['original_sentences_count']}"
                )
                click.echo(
                    f"  üìÑ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_sentences_count']}"
                )
                click.echo(
                    f"  üìâ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['compression_ratio']:.1%}"
                )
                click.echo(f"  üî§ –ò—Å—Ö–æ–¥–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤: {stats['original_chars_count']:,}")
                click.echo(f"  ‚úÇÔ∏è –°–∏–º–≤–æ–ª–æ–≤ –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_chars_count']:,}")
                click.echo(
                    f"  üìä –°–æ–∫—Ä–∞—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞: {stats['chars_compression_ratio']:.1%}"
                )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
        if output:
            output_path = Path(output)
            try:
                with open(output_path, "w", encoding="utf-8") as f:
                    f.write(f"–í—ã–∂–∏–º–∫–∞ —Ñ–∞–π–ª–∞: {file_path.name}\n")
                    f.write(
                        f"–°–æ–∑–¥–∞–Ω–æ: {click.get_current_context().meta.get('timestamp', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n"
                    )
                    f.write("=" * 60 + "\n\n")

                    for i, sentence in enumerate(summary, 1):
                        f.write(f"{i}. {sentence.strip()}\n\n")

                    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ —Ñ–∞–π–ª
                    if "stats" in locals():
                        f.write("\n" + "=" * 60 + "\n")
                        f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–ò\n")
                        f.write("=" * 60 + "\n")
                        f.write(
                            f"–ò—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['original_sentences_count']}\n"
                        )
                        f.write(
                            f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_sentences_count']}\n"
                        )
                        f.write(
                            f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['compression_ratio']:.1%}\n"
                        )
                        f.write(
                            f"–ò—Å—Ö–æ–¥–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤: {stats['original_chars_count']:,}\n"
                        )
                        f.write(
                            f"–°–∏–º–≤–æ–ª–æ–≤ –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_chars_count']:,}\n"
                        )
                        f.write(
                            f"–°–æ–∫—Ä–∞—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞: {stats['chars_compression_ratio']:.1%}\n"
                        )

                click.echo(f"üíæ –í—ã–∂–∏–º–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {output_path}")

            except Exception as e:
                click.echo(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤—ã–∂–∏–º–∫–∏: {e}")

    except Exception as e:
        click.echo(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤—ã–∂–∏–º–∫–∏: {e}")
        logger.error(f"–û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")


@cli.command()
@click.option("--text", "-t", required=True, help="–¢–µ–∫—Å—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏")
@click.option("--model", "-m", default="doc2vec_model", help="–ò–º—è Doc2Vec –º–æ–¥–µ–ª–∏")
@click.option("--sentences", "-s", default=5, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ")
@click.option("--output", "-o", help="–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∂–∏–º–∫–∏")
def summarize_text(
    text: str, model: str, sentences: int, output: Optional[str]
) -> None:
    """
    –°–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫—É –∏–∑ —Ç–µ–∫—Å—Ç–∞

    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (—Å—Ç—Ä–æ–∫–∞)
        model: –ò–º—è Doc2Vec –º–æ–¥–µ–ª–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        sentences: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ
        output: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∂–∏–º–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """
    # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    if not text or len(text.strip()) < 100:
        click.echo("‚ùå –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (–º–∏–Ω–∏–º—É–º 100 —Å–∏–º–≤–æ–ª–æ–≤)")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
    temp_processor = TextSummarizer()
    original_sentences = temp_processor.text_processor.split_into_sentences(text)

    if len(original_sentences) <= sentences:
        click.echo(
            f"‚ö†Ô∏è –í —Ç–µ–∫—Å—Ç–µ –≤—Å–µ–≥–æ {len(original_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —á—Ç–æ –º–µ–Ω—å—à–µ –∏–ª–∏ —Ä–∞–≤–Ω–æ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É ({sentences})"
        )
        click.echo("–í—ã–≤–æ–¥–∏–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç:")
        for i, sentence in enumerate(original_sentences, 1):
            click.echo(f"{i}. {sentence.strip()}")
        return

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Doc2Vec
    trainer = Doc2VecTrainer()
    loaded_model = trainer.load_model(model)

    if loaded_model is None:
        click.echo("‚ö†Ô∏è –ú–æ–¥–µ–ª—å Doc2Vec –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è")
        summarizer = TextSummarizer()
    else:
        click.echo("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å Doc2Vec")
        summarizer = TextSummarizer(loaded_model)

    logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –≤—ã–∂–∏–º–∫–∏ —Ç–µ–∫—Å—Ç–∞")

    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã–∂–∏–º–∫–∏
        summary = summarizer.summarize_text(text, sentences_count=sentences)

        if not summary:
            click.echo("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫—É")
            return

        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        click.echo("\nüìÑ –í—ã–∂–∏–º–∫–∞ —Ç–µ–∫—Å—Ç–∞:")
        click.echo("=" * 60)

        for i, sentence in enumerate(summary, 1):
            click.echo(f"{i}. {sentence.strip()}")
            click.echo()  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        stats = summarizer.get_summary_statistics(text, summary)

        click.echo("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:")
        click.echo("-" * 30)
        click.echo(f"  üìë –ò—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['original_sentences_count']}")
        click.echo(f"  üìÑ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_sentences_count']}")
        click.echo(
            f"  üìâ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['compression_ratio']:.1%}"
        )
        click.echo(f"  üî§ –ò—Å—Ö–æ–¥–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤: {stats['original_chars_count']:,}")
        click.echo(f"  ‚úÇÔ∏è –°–∏–º–≤–æ–ª–æ–≤ –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_chars_count']:,}")
        click.echo(f"  üìä –°–æ–∫—Ä–∞—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞: {stats['chars_compression_ratio']:.1%}")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
        if output:
            output_path = Path(output)
            try:
                with open(output_path, "w", encoding="utf-8") as f:
                    f.write("–í—ã–∂–∏–º–∫–∞ —Ç–µ–∫—Å—Ç–∞\n")
                    f.write("=" * 60 + "\n\n")

                    for i, sentence in enumerate(summary, 1):
                        f.write(f"{i}. {sentence.strip()}\n\n")

                    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    f.write("\n" + "=" * 60 + "\n")
                    f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–£–ú–ú–ê–†–ò–ó–ê–¶–ò–ò\n")
                    f.write("=" * 60 + "\n")
                    f.write(
                        f"–ò—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['original_sentences_count']}\n"
                    )
                    f.write(
                        f"–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_sentences_count']}\n"
                    )
                    f.write(
                        f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['compression_ratio']:.1%}\n"
                    )
                    f.write(f"–ò—Å—Ö–æ–¥–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤: {stats['original_chars_count']:,}\n")
                    f.write(f"–°–∏–º–≤–æ–ª–æ–≤ –≤ –≤—ã–∂–∏–º–∫–µ: {stats['summary_chars_count']:,}\n")
                    f.write(
                        f"–°–æ–∫—Ä–∞—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞: {stats['chars_compression_ratio']:.1%}\n"
                    )

                click.echo(f"üíæ –í—ã–∂–∏–º–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {output_path}")

            except Exception as e:
                click.echo(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤—ã–∂–∏–º–∫–∏: {e}")

    except Exception as e:
        click.echo(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤—ã–∂–∏–º–∫–∏: {e}")
        logger.error(f"–û—à–∏–±–∫–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")


@cli.command()
@click.option("--documents", "-d", required=True, help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
@click.option("--model", "-m", default="doc2vec_model", help="–ò–º—è Doc2Vec –º–æ–¥–µ–ª–∏")
@click.option(
    "--sentences",
    "-s",
    default=3,
    help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –≤—ã–∂–∏–º–∫–µ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞",
)
@click.option("--output-dir", "-o", help="–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∂–∏–º–æ–∫")
@click.option(
    "--extensions", default="pdf,docx,doc", help="–†–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)"
)
@click.option(
    "--max-files",
    default=0,
    help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ)",
)
def summarize_batch(
    documents: str,
    model: str,
    sentences: int,
    output_dir: Optional[str],
    extensions: str,
    max_files: int,
) -> None:
    """
    –°–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫–∏ –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –ø–∞–ø–∫–µ

    Args:
        documents: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        model: –ò–º—è Doc2Vec –º–æ–¥–µ–ª–∏
        sentences: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –∫–∞–∂–¥–æ–π –≤—ã–∂–∏–º–∫–µ
        output_dir: –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–∂–∏–º–æ–∫
        extensions: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
        max_files: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ (0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)
    """
    documents_path = Path(documents)
    if not documents_path.exists():
        click.echo(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {documents_path}")
        return

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Doc2Vec
    trainer = Doc2VecTrainer()
    loaded_model = trainer.load_model(model)

    if loaded_model is None:
        click.echo("‚ö†Ô∏è –ú–æ–¥–µ–ª—å Doc2Vec –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è")
        summarizer = TextSummarizer()
    else:
        click.echo("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å Doc2Vec")
        summarizer = TextSummarizer(loaded_model)

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
    allowed_extensions = {f".{ext.strip().lower()}" for ext in extensions.split(",")}
    click.echo(f"üîç –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏: {allowed_extensions}")

    # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤
    all_files = []
    for file_path in documents_path.rglob("*"):
        if file_path.is_file() and file_path.suffix.lower() in allowed_extensions:
            all_files.append(file_path)

    if not all_files:
        click.echo(f"‚ùå –§–∞–π–ª—ã —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ {allowed_extensions} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤
    if max_files > 0 and len(all_files) > max_files:
        all_files = all_files[:max_files]
        click.echo(f"üìÅ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ –¥–æ {max_files} —Ñ–∞–π–ª–æ–≤ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö")

    click.echo(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(all_files)}")

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–∞–ø–∫–∏ –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    if output_dir:
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True, parents=True)
        click.echo(f"üíæ –í—ã–∂–∏–º–∫–∏ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")
    else:
        click.echo("üì∫ –í—ã–∂–∏–º–∫–∏ –±—É–¥—É—Ç –≤—ã–≤–µ–¥–µ–Ω—ã —Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Å–æ–ª—å")

    successful = 0
    failed = 0

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
    for i, file_path in enumerate(all_files, 1):
        click.echo(f"\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {i}/{len(all_files)}: {file_path.name}")

        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã–∂–∏–º–∫–∏
            summary = summarizer.summarize_file(
                str(file_path), sentences_count=sentences
            )

            if not summary:
                click.echo(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤—ã–∂–∏–º–∫—É –¥–ª—è {file_path.name}")
                failed += 1
                continue

            # –ö—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
            click.echo(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–∞ –≤—ã–∂–∏–º–∫–∞: {len(summary)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∫–∞–∫ –ø—Ä–µ–≤—å—é
            if summary:
                preview = (
                    summary[0][:100] + "..." if len(summary[0]) > 100 else summary[0]
                )
                click.echo(f"   üëÅÔ∏è –ü—Ä–µ–≤—å—é: {preview}")

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
            if output_dir:
                summary_filename = f"{file_path.stem}_summary.txt"
                summary_path = output_path / summary_filename

                try:
                    with open(summary_path, "w", encoding="utf-8") as f:
                        f.write(f"–í—ã–∂–∏–º–∫–∞ —Ñ–∞–π–ª–∞: {file_path.name}\n")
                        f.write(f"–ò—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å: {file_path}\n")
                        f.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {len(summary)}\n")
                        f.write("=" * 60 + "\n\n")

                        for j, sentence in enumerate(summary, 1):
                            f.write(f"{j}. {sentence.strip()}\n\n")

                    click.echo(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {summary_filename}")
                except Exception as save_error:
                    click.echo(f"   ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {save_error}")
                    failed += 1
                    continue

            successful += 1

        except Exception as e:
            click.echo(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {file_path}: {e}")
            failed += 1

    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    click.echo("\nüìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:")
    click.echo("=" * 50)
    click.echo(f"  ‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {successful}")
    click.echo(f"  ‚ùå –û—à–∏–±–æ–∫: {failed}")
    click.echo(f"  üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(all_files)}")
    click.echo(f"  üìà –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {(successful / len(all_files) * 100):.1f}%")

    if output_dir and successful > 0:
        click.echo(f"  üíæ –í—ã–∂–∏–º–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")


@cli.command()
def status():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –≤—ã–ø–æ–ª–Ω—è—é—â–∏—Ö—Å—è –∑–∞–¥–∞—á"""

    tasks = task_manager.get_all_tasks()

    if not tasks:
        click.echo("üì≠ –ê–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á –Ω–µ—Ç")
        return

    click.echo("üìã –°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á:")
    click.echo("=" * 60)

    for task in tasks:
        status_icon = {
            "pending": "‚è≥",
            "running": "üîÑ",
            "completed": "‚úÖ",
            "failed": "‚ùå",
            "cancelled": "‚èπÔ∏è",
        }.get(task.status.value, "‚ùì")

        click.echo(f"{status_icon} {task.name}")
        click.echo(f"   ID: {task.id}")
        click.echo(f"   –°—Ç–∞—Ç—É—Å: {task.status.value}")

        if task.progress > 0:
            progress_bar = "‚ñà" * int(task.progress * 20) + "‚ñë" * (
                20 - int(task.progress * 20)
            )
            click.echo(f"   –ü—Ä–æ–≥—Ä–µ—Å—Å: [{progress_bar}] {task.progress:.1%}")

        if task.duration:
            click.echo(f"   –í—Ä–µ–º—è: {task.duration:.1f}—Å")

        if task.error:
            click.echo(f"   –û—à–∏–±–∫–∞: {task.error}")

        click.echo()


@cli.command()
@click.argument("task_id")
def cancel(task_id: str):
    """–û—Ç–º–µ–Ω–∞ –∑–∞–¥–∞—á–∏"""

    if task_manager.cancel_task(task_id):
        click.echo(f"‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –æ—Ç–º–µ–Ω–µ–Ω–∞")
    else:
        click.echo(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–º–µ–Ω–∏—Ç—å –∑–∞–¥–∞—á—É {task_id}")


@cli.command()
@click.option(
    "--max-keep", default=50, help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è"
)
def cleanup(max_keep: int):
    """–û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á"""

    before_count = len(task_manager.get_all_tasks())
    task_manager.cleanup_finished_tasks(max_keep)
    after_count = len(task_manager.get_all_tasks())

    removed = before_count - after_count
    click.echo(f"üßπ –£–¥–∞–ª–µ–Ω–æ {removed} –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á")


@cli.command()
@click.option("--documents", "-d", help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
@click.option("--output", "-o", help="–§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞")
def system_info(documents: Optional[str], output: Optional[str]):
    """–°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞"""

    info_lines = []

    # –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    system_info = performance_monitor.get_system_info()
    info_lines.extend(
        [
            "üñ•Ô∏è –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:",
            f"   CPU: {system_info['cpu_count']} —è–¥–µ—Ä, –∑–∞–≥—Ä—É–∑–∫–∞ {system_info['cpu_percent']}%",
            f"   –û–ó–£: {system_info['memory_available']:.1f}/{system_info['memory_total']:.1f} –ì–ë —Å–≤–æ–±–æ–¥–Ω–æ",
            f"   –î–∏—Å–∫: {100 - system_info['disk_usage']:.1f}% —Å–≤–æ–±–æ–¥–Ω–æ",
            "",
        ]
    )

    # –°—Ç–∞—Ç—É—Å SpaCy
    spacy_info = check_spacy_model_availability()
    spacy_status = "‚úÖ –ì–æ—Ç–æ–≤" if spacy_info["model_loadable"] else "‚ùå –ù–µ –≥–æ—Ç–æ–≤"
    info_lines.extend(
        [
            "üß† –Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å:",
            f"   SpaCy: {spacy_status}",
            f"   –ú–æ–¥–µ–ª—å: {SPACY_MODEL}",
            "",
        ]
    )

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
    if documents:
        try:
            docs_path = Path(documents)
            if docs_path.exists():
                file_extractor = FileExtractor()
                found_files = file_extractor.find_documents(docs_path)

                # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤
                valid_files = 0
                invalid_files = 0
                total_size = 0

                for file_path in found_files:
                    validation = FileValidator.validate_document_file(file_path)
                    if validation["valid"]:
                        valid_files += 1
                        total_size += validation["file_info"]["size"]
                    else:
                        invalid_files += 1

                info_lines.extend(
                    [
                        "üìÅ –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:",
                        f"   –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(found_files)}",
                        f"   –í–∞–ª–∏–¥–Ω—ã—Ö: {valid_files}",
                        f"   –° –æ—à–∏–±–∫–∞–º–∏: {invalid_files}",
                        f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_size / 1024 / 1024:.1f} –ú–ë",
                        "",
                    ]
                )

        except Exception as e:
            info_lines.extend(["üìÅ –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:", f"   ‚ùå –û—à–∏–±–∫–∞: {e}", ""])

    # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    if performance_monitor.metrics:
        info_lines.extend(
            [
                "‚ö° –ü–æ—Å–ª–µ–¥–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏:",
            ]
        )

        for op_name, metrics in list(performance_monitor.metrics.items())[-5:]:
            info_lines.append(f"   {op_name}: {metrics['duration']:.2f}—Å")

        info_lines.append("")

    # –ê–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏
    running_tasks = task_manager.get_running_tasks()
    if running_tasks:
        info_lines.extend(
            [
                "üîÑ –ê–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏:",
            ]
        )

        for task in running_tasks:
            info_lines.append(f"   {task.name}: {task.progress:.1%}")

        info_lines.append("")

    report = "\n".join(info_lines)

    # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
    click.echo(report)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
    if output:
        try:
            with open(output, "w", encoding="utf-8") as f:
                f.write(f"–°–∏—Å—Ç–µ–º–Ω—ã–π –æ—Ç—á–µ—Ç - {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write("=" * 60 + "\n\n")
                f.write(report)

            click.echo(f"üíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output}")

        except Exception as e:
            click.echo(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")


@cli.command()
@click.option("--show", is_flag=True, help="–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é")
@click.option("--reset", is_flag=True, help="–°–±—Ä–æ—Å–∏—Ç—å –∫ –∑–Ω–∞—á–µ–Ω–∏—è–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
@click.option("--reload", is_flag=True, help="–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–∞")
@click.option(
    "--set", nargs=2, multiple=True, help="–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä: --set key value"
)
def config(show: bool, reset: bool, reload: bool, set: tuple):
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""

    from semantic_search.config import config_manager

    if reset:
        if click.confirm(
            "–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ —Å–±—Ä–æ—Å–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∫ –∑–Ω–∞—á–µ–Ω–∏—è–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é?"
        ):
            config_manager.reset_to_defaults()
            click.echo("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–±—Ä–æ—à–µ–Ω–∞ –∫ –∑–Ω–∞—á–µ–Ω–∏—è–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        else:
            click.echo("‚ùå –°–±—Ä–æ—Å –æ—Ç–º–µ–Ω–µ–Ω")
        return

    if reload:
        config_manager.reload_config()
        click.echo("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ —Ñ–∞–π–ª–∞")

    if set:
        for key, value in set:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø
            try:
                # –ß–∏—Å–ª–∞
                if value.isdigit():
                    value = int(value)
                elif value.replace(".", "", 1).isdigit():
                    value = float(value)
                # –ë—É–ª–µ–≤—ã –∑–Ω–∞—á–µ–Ω–∏—è
                elif value.lower() in ("true", "false"):
                    value = value.lower() == "true"
                # –ß–∏—Å–ª–∞ —Å –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏—è–º–∏
                elif "_" in value and value.replace("_", "").isdigit():
                    value = int(value.replace("_", ""))

            except Exception:
                pass  # –û—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–∫—Ü–∏—é –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä
            if "." in key:
                section, param = key.split(".", 1)
                config_manager.update_config(**{section: {param: value}})
                click.echo(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ: {section}.{param} = {value}")
            else:
                click.echo("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–ª—é—á–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: section.parameter")

    if show or (not reset and not reload and not set):
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        current_config = config_manager.config

        click.echo("\nüìã –¢–µ–∫—É—â–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
        click.echo("=" * 60)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        click.echo("\nüìù –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ (text_processing):")
        for key, value in current_config.text_processing.items():
            if isinstance(value, int) and value > 1000:
                click.echo(f"  {key}: {value:,}")
            else:
                click.echo(f"  {key}: {value}")

        # Doc2Vec
        click.echo("\nüß† –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Doc2Vec (doc2vec):")
        for key, value in current_config.doc2vec.items():
            click.echo(f"  {key}: {value}")

        # –ü–æ–∏—Å–∫
        click.echo("\nüîç –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ (search):")
        for key, value in current_config.search.items():
            click.echo(f"  {key}: {value}")

        # GUI
        click.echo("\nüíª –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ (gui):")
        for key, value in current_config.gui.items():
            click.echo(f"  {key}: {value}")

        # –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
        click.echo("\nüìÑ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (summarization):")
        for key, value in current_config.summarization.items():
            click.echo(f"  {key}: {value}")

        click.echo("\nüí° –ü—Ä–∏–º–µ—Ä—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:")
        click.echo(
            "  semantic-search-cli config --set text_processing.max_text_length 10000000"
        )
        click.echo("  semantic-search-cli config --set doc2vec.vector_size 200")
        click.echo("  semantic-search-cli config --set search.default_top_k 20")


def cli_mode():
    """–ó–∞–ø—É—Å–∫ CLI —Ä–µ–∂–∏–º–∞"""
    cli()


if __name__ == "__main__":
    if len(sys.argv) > 1:
        cli_mode()
    else:
        main()
