% prilozheniya.tex - Приложения

\nonumchapter{ПРИЛОЖЕНИЕ А}

\section*{Листинг модуля обработки документов}


\begin{manuallisting}[language=Python]{Листинг А.1 --- Основной модуль системы семантического поиска}
	import os
	import sys
	from pathlib import Path
	from typing import List, Dict, Optional
	
	import numpy as np
	from gensim.models import Doc2Vec
	from gensim.models.doc2vec import TaggedDocument
	import spacy
	
	class SemanticSearchEngine:
	"""
	Основной класс системы семантического поиска
	"""
	def __init__(self, model_path: Optional[str] = None):
	"""
	Инициализация поисковой системы
	
	Args:
	model_path: путь к предобученной модели Doc2Vec
	"""
	self.model = None
	self.documents = []
	self.nlp = spacy.load("ru_core_news_sm")
	
	if model_path and os.path.exists(model_path):
	self.load_model(model_path)
	
	def preprocess_text(self, text: str) -> List[str]:
	"""
	Предобработка текста для модели
	
	Args:
	text: исходный текст
	
	Returns:
	Список токенов
	"""
	doc = self.nlp(text.lower())
	tokens = []
	
\end{manuallisting}

\clearpage

% Продолжение на следующей странице
\begin{manuallisting}[language=Python, firstnumber=42]{Продолжение листинга А.1}
	for token in doc:
	if not token.is_stop and not token.is_punct and not token.is_space:
	tokens.append(token.lemma_)
	
	return tokens
	
	def train_model(self, documents: List[Dict[str, str]], 
	vector_size: int = 300,
	min_count: int = 2,
	epochs: int = 40):
	"""
	Обучение модели Doc2Vec
	
	Args:
	documents: список документов для обучения
	vector_size: размерность векторов
	min_count: минимальная частота слов
	epochs: количество эпох обучения
	"""
	# Подготовка данных
	tagged_data = []
	for i, doc in enumerate(documents):
	tokens = self.preprocess_text(doc['text'])
	tagged_data.append(TaggedDocument(tokens, [i]))
	
	self.documents = documents
	
	# Создание и обучение модели
	self.model = Doc2Vec(
	vector_size=vector_size,
	min_count=min_count,
	epochs=epochs,
	dm=1,
	dbow_words=1,
	workers=4
	)
	
	self.model.build_vocab(tagged_data)
	self.model.train(tagged_data, 
	total_examples=self.model.corpus_count,
	epochs=self.model.epochs)
	
	def search(self, query: str, top_k: int = 10) -> List[Dict[str, any]]:
	"""
	Поиск документов по запросу
\end{manuallisting}

\clearpage

\begin{manuallisting}[language=Python, firstnumber=88]{Продолжение листинга А.1}
	Args:
	query: поисковый запрос
	top_k: количество результатов
	
	Returns:
	Список найденных документов с оценками релевантности
	"""
	if not self.model:
	raise ValueError("Модель не обучена")
	
	# Векторизация запроса
	query_tokens = self.preprocess_text(query)
	query_vector = self.model.infer_vector(query_tokens)
	
	# Поиск похожих документов
	similar_docs = self.model.dv.most_similar([query_vector], topn=top_k)
	
	results = []
	for doc_id, score in similar_docs:
	result = {
		'document': self.documents[doc_id],
		'score': float(score),
		'rank': len(results) + 1
	}
	results.append(result)
	
	return results
	
	def save_model(self, path: str):
	"""
	Сохранение обученной модели
	"""
	if self.model:
	self.model.save(path)
	
	def load_model(self, path: str):
	"""
	Загрузка обученной модели
	"""
	self.model = Doc2Vec.load(path)
\end{manuallisting}


\clearpage


\nonumchapter{ПРИЛОЖЕНИЕ Б}

Результаты тестирования системы:


\tabcaption{Б.1}{Сравнение производительности поисковых систем}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|c|c|c|c|}
			\hline
			\textbf{Метод} & \textbf{Precision@10} & \textbf{Recall@10} & \textbf{F1-мера} & \textbf{Время, мс} \\
			\hline
			TF-IDF & 0.72 & 0.68 & 0.70 & 125 \\
			\hline
			BM25 & 0.78 & 0.74 & 0.76 & 142 \\
			\hline
			Doc2Vec (наш) & 0.85 & 0.82 & 0.83 & 198 \\
			\hline
		\end{tabular}
	\end{center}

\end{table}

\vspace{1cm}

\tabcaption{Б.2}{Результаты тестирования на различных коллекциях документов}
\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|c|c|c|}
			\hline
			\textbf{Коллекция} & \textbf{Размер} & \textbf{MAP} & \textbf{MRR} \\
			\hline
			Научные статьи & 10,000 & 0.834 & 0.867 \\
			\hline
			Новостные тексты & 25,000 & 0.812 & 0.845 \\
			\hline
			Юридические документы & 15,000 & 0.856 & 0.881 \\
			\hline
			Техническая документация & 8,000 & 0.871 & 0.892 \\
			\hline
		\end{tabular}
	\end{center}

\end{table}

\nonumchapter{ПРИЛОЖЕНИЕ В}

Презентация к выпускной квалификационной работе состоит из \underline{\hspace{0.5cm}} слайдов.